## Packages

import warnings
warnings.filterwarnings("ignore")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
import os

from sklearn.utils import resample
from sklearn.model_selection import train_test_split

import keras
from keras.preprocessing.text import Tokenizer
from keras.utils import pad_sequences
from keras.utils.np_utils import to_categorical
from sklearn.preprocessing import LabelEncoder
from keras.utils.np_utils import to_categorical
from keras.models import Model, Sequential
from keras.callbacks import EarlyStopping
from keras.layers import Input, Dense, Dropout
from keras.layers import Embedding, Bidirectional, LSTM

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

!pip install umap-learn[plot]
!pip install lime

import keras
from lime.lime_text import LimeTextExplainer
from collections import OrderedDict
import seaborn as sns

from umap import UMAP
from sklearn.decomposition import PCA
import umap
import umap.plot
from bokeh.plotting import show, save, output_notebook, output_file

from scipy.stats import ttest_ind
from scipy.stats import t
import scipy.stats as stats
from scipy.special import kl_div

## Preprocessing

### Data

df1 = pd.read_excel('/content/drive/MyDrive/Misclassified/Data/data_ncbi.xlsx')
df2 = pd.read_excel('/content/drive/MyDrive/Misclassified/Data/data_Flu_DB.xlsx')

combined_df = pd.concat([df1, df2])
combined_df.drop_duplicates(subset=['Accession', 'Sequence'], inplace=True)

unique_df = combined_df[['Accession', 'Database', 'Segment', 'Host', 'Sequence']]
unique_df.to_excel('/content/drive/MyDrive/Misclassified/Data/unique_df.xlsx', index=False)

count_df = unique_df.groupby(['Segment', 'Host']).size().reset_index(name='Count')
print(count_df)

count_df = unique_df.groupby('Host').size().reset_index(name='Count')
print(count_df)

### Undersampling

avian_df = unique_df[unique_df['Host'] == 'Avian']
human_df = unique_df[unique_df['Host'] == 'Human']
swine_df = unique_df[unique_df['Host'] == 'Swine']

avian_df = resample(avian_df, n_samples=116636, random_state=0)
human_df = resample(human_df, n_samples=116636, random_state=0)

undersampled_df = pd.concat([avian_df, human_df, swine_df])
undersampled_df.to_excel('/content/drive/MyDrive/Misclassified/Data/undersampled_df.xlsx', index=False)

count_df = undersampled_df.groupby(['Segment', 'Host']).size().reset_index(name='Count')
print(count_df)

### Split

train_df, val_test_df = train_test_split(undersampled_df, test_size=0.3, random_state=42)
val_df, test_df = train_test_split(val_test_df, test_size=0.5, random_state=42)

print(f'Train set shape: {train_df.shape}')
print(f'Validation set shape: {val_df.shape}')
print(f'Test set shape: {test_df.shape}')

count_df_train = train_df.groupby(['Segment', 'Host']).size().reset_index(name='Count')
print(count_df_train)

count_df_val = val_df.groupby(['Segment', 'Host']).size().reset_index(name='Count')
print(count_df_val)

count_df_val = val_df.groupby(['Segment', 'Host']).size().reset_index(name='Count')
print(count_df_val)

count_df_test = test_df.groupby(['Segment', 'Host']).size().reset_index(name='Count')
print(count_df_test)

train_df.to_excel('/content/drive/MyDrive/Misclassified/Data/train_df.xlsx', index=False)
val_df.to_excel('/content/drive/MyDrive/Misclassified/Data/val_df.xlsx', index=False)
test_df.to_excel('/content/drive/MyDrive/Misclassified/Data/test_df.xlsx', index=False)

### Remove Zoonose

train_df = pd.read_excel('/content/drive/MyDrive/Nissrine/Misclassified/train_df.xlsx')
val_df = pd.read_excel('/content/drive/MyDrive/Nissrine/Misclassified/val_df.xlsx')
test_df = pd.read_excel('/content/drive/MyDrive/Nissrine/Misclassified/test_df.xlsx')

len(train_df), len(val_df), len(test_df)

accessions = []
with open('/content/drive/MyDrive/Nissrine/Misclassified/accessions_zonoose.txt', 'r') as f:
    for line in f:
        accessions.append(line.strip())

print(accessions)

len(accessions)

train_df = train_df[~train_df['Accession'].isin(accessions)]
val_df = val_df[~val_df['Accession'].isin(accessions)]
test_df = test_df[~test_df['Accession'].isin(accessions)]

len(train_df), len(val_df), len(test_df)

train_df.to_excel('/content/drive/MyDrive/Nissrine/Misclassified/train_df.xlsx', index=False)
val_df.to_excel('/content/drive/MyDrive/Nissrine/Misclassified/val_df.xlsx', index=False)
test_df.to_excel('/content/drive/MyDrive/Nissrine/Misclassified/test_df.xlsx', index=False)

### Discarded Sequences

zoonose_df = pd.read_excel('/content/drive/MyDrive/Misclassified/Data/zoonotic_seq_df.xlsx')

dfs_to_compare = [train_df, val_df, test_df, zoonose_df]

for df in dfs_to_compare:
    df.drop_duplicates(subset=["Accession"], keep=False, inplace=True)
    unique_df = unique_df[~unique_df.Accession.isin(df.Accession)]

unique_df.to_excel("/content/drive/MyDrive/Misclassified/Data/discarded_seq_df.xlsx", index=False)
len(unique_df)

### Open Reading Frame

train_df = pd.read_excel('/content/drive/MyDrive/Nissrine/Misclassified/train_df.xlsx')
val_df = pd.read_excel('/content/drive/MyDrive/Nissrine/Misclassified/val_df.xlsx')
test_df = pd.read_excel('/content/drive/MyDrive/Nissrine/Misclassified/test_df.xlsx')

def codonStart(X,y):
  seq = X
  host = y.to_list()

  N = []
  X_ = []
  y_ = []

  numero = 0
  numbis = 0
  for i in range(len(seq)):
    seq_ = seq[i]
    host_ = host[i]

    numero = 0
    numbis = 0
    while numero < len(seq_)-2:
        if seq_[numero:numero+3] == 'ATG':
            numbis = numero
            N.append(numbis)
            X_.append(seq_)
            y_.append(host_)

            break
        numero += 1
  return (X_, y_, N)

X_train, y_train, idxStart_train = codonStart(train_df.Sequence, train_df.Host)
X_val, y_val, idxStart_val = codonStart(val_df.Sequence, val_df.Host)
X_test, y_test, idxStart_test = codonStart(test_df.Sequence, test_df.Host)

nonStop = ['GCT', 'GCC', 'GCA', 'GCG', 'CGT', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG', 'AAT', 'AAC', 'GAT', 'GAC', 'TGT', 'TGC', 'CAA', 'CAG', 'GAA', 'GAG', 'GGT', 'GGC', 'GGA', 'GGG', 'CAT', 'CAC', 'ATT', 'ATC', 'ATA', 'TTA', 'TTG', 'CTT', 'CTC', 'CTA', 'CTG', 'AAA', 'AAG', 'ATG', 'TTT', 'TTC', 'CCT', 'CCC', 'CCA', 'CCG', 'TCT', 'TCC', 'TCA', 'TCG', 'AGT', 'AGC', 'ACT', 'ACC', 'ACA', 'ACG', 'TGG', 'TAT', 'TAC', 'GTT', 'GTC', 'GTA', 'GTG']
stop = ['TAG', 'TGA', 'TAA']

def toSeq(X, N):
  seq_ = []
  tmp = []
  for i in range(len(X)):
    seq = X[i]
    numbis = N[i]
    while numbis < len(seq)-2:
      if seq[numbis:numbis+3] in nonStop:
        tmp += seq[numbis:numbis+3]
      elif seq[numbis:numbis+3] in stop:
        break

      numbis += 3
    str = ""
    seq_.append(str.join(tmp))
    tmp=[]

  return(seq_)

seq_train = toSeq(X_train, idxStart_train)
seq_val = toSeq(X_val, idxStart_val)
seq_test = toSeq(X_test, idxStart_test)

seq_train[0]

# Calculate the length of each sequence and find the maximum length
seq_lengths = [len(seq) for seq in seq_train]
max_length = max(seq_lengths)
max_length

# Find the ID(s) of the sequence(s) with the maximum length
max_seq_ids = [i for i, seq in enumerate(seq_train) if len(seq) == max_length]
max_seq_ids

seq_train[209353]

query_sequence = seq_train[209353]

matching_idx = -1
for idx, seq in train_df['Sequence'].iteritems():
    if query_sequence == seq:
        matching_idx = idx
        break

if matching_idx != -1:
    print(f"The ID of the matching sequence in train_df is {matching_idx}.")
else:
    print("No matching sequence found in train_df.")


(train_df.Segment[209355])

### Length

def length(data):
  length = []
  for i in range(len(data)):
    length.append(len(data[i]))

  min = int(np.min(length))
  max = int(np.max(length))
  median = int(np.median(length))

  return (min, max, median)

min_length_train, max_length_train, median_length_train = length(seq_train)
min_length_val, max_length_val, median_length_val = length(seq_val)
min_length_test, max_length_test, median_length_test = length(seq_test)

min_length=min(min_length_train, min_length_val, min_length_test)
max_length=max(max_length_train, max_length_val, max_length_test)

print("Taille Minimale des séquences : ", min_length)
print("Taille Maximale des séquences : ", max_length)

## Encoding

### Labels

le = LabelEncoder()

train_labels = le.fit_transform(y_train)
val_labels = le.transform(y_val)
test_labels = le.transform(y_test)

train_labels = to_categorical(train_labels)
val_labels = to_categorical(val_labels)
test_labels = to_categorical(test_labels)

print("Training   : ", train_labels.shape)
print("Validation : ", val_labels.shape)
print("Test       : ", test_labels.shape)

### Proteins

genetic_code = {
    "ATA":"I", "ATC":"I", "ATT":"I", "ATG":"M",
    "ACA":"T", "ACC":"T", "ACG":"T", "ACT":"T",
    "AAC":"N", "AAT":"N", "AAA":"K", "AAG":"K",
    "AGC":"S", "AGT":"S", "AGA":"R", "AGG":"R",
    "CTA":"L", "CTC":"L", "CTG":"L", "CTT":"L",
    "CCA":"P", "CCC":"P", "CCG":"P", "CCT":"P",
    "CAC":"H", "CAT":"H", "CAA":"Q", "CAG":"Q",
    "CGA":"R", "CGC":"R", "CGG":"R", "CGT":"R",
    "GTA":"V", "GTC":"V", "GTG":"V", "GTT":"V",
    "GCA":"A", "GCC":"A", "GCG":"A", "GCT":"A",
    "GAC":"D", "GAT":"D", "GAA":"E", "GAG":"E",
    "GGA":"G", "GGC":"G", "GGG":"G", "GGT":"G",
    "TCA":"S", "TCC":"S", "TCG":"S", "TCT":"S",
    "TTC":"F", "TTT":"F", "TTA":"L", "TTG":"L",
    "TAC":"Y", "TAT":"Y", "TAA":"*", "TAG":"*",
    "TGC":"C", "TGT":"C", "TGA":"*", "TGG":"W",
}

def toProtein(X):
  seq_pro=[]
  for rna_sequence in X:
      codons = [rna_sequence[i:i+3] for i in range(0, len(rna_sequence), 3)]
        
      amino_acids = [genetic_code[codon] for codon in codons]
        
      protein_sequence = ''.join(amino_acids)
      seq_pro.append(protein_sequence)
      
  return seq_pro

seq_pro_train = toProtein(seq_train)
seq_pro_val = toProtein(seq_val)
seq_pro_test = toProtein(seq_test)

seq_pro_train[0]

aa_alphabet = {'A': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10, 'M': 11, 'N': 12, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'V': 18, 'W': 19, 'Y': 20}

def encode_sequence_pro(seq_list):
    encoded_seqs = []
    for seq in seq_list:
        encoded_seq = [aa_alphabet[aa] for aa in seq]
        encoded_seqs.append(encoded_seq)
    return encoded_seqs

train_sequences_pro = encode_sequence_pro(seq_pro_train)
val_sequences_pro = encode_sequence_pro(seq_pro_val)
test_sequences_pro = encode_sequence_pro(seq_pro_test)

seq_pro_train[0]

print(train_sequences_pro[0])

min_length_pro, max_length_pro, median_length_pro = length(train_sequences_pro)
print("Taille Maximale des séquences : ", max_length_pro)

train_padded_pro = pad_sequences(train_sequences_pro, maxlen=(max_length_pro), padding="post", truncating="post")
val_padded_pro = pad_sequences(val_sequences_pro, maxlen=(max_length_pro), padding="post", truncating="post")
test_padded_pro = pad_sequences(test_sequences_pro, maxlen=(max_length_pro), padding="post", truncating="post")

print("Training   : ", train_padded_pro.shape)
print("Validation : ", val_padded_pro.shape)
print("Test       : ", test_padded_pro.shape)

### RNA

codon_index = {
    'TTT': 1, 'TTC': 2, 'TTA': 3, 'TTG': 4, 'CTT': 5, 'CTC': 6, 'CTA': 7, 'CTG': 8, 'ATT': 9, 'ATC': 10, 'ATA': 11, 'ATG': 12, 'GTT': 13, 'GTC': 14, 'GTA': 15, 'GTG': 16, 'TCT': 17, 'TCC': 18, 'TCA': 19, 'TCG': 20, 'CCT': 21, 'CCC': 22, 'CCA': 23, 'CCG': 24, 'ACT': 25, 'ACC': 26, 'ACA': 27, 'ACG': 28, 'GCT': 29, 'GCC': 30, 'GCA': 31, 'GCG': 32, 'TAT': 33, 'TAC': 34, 'CAT': 35, 'CAC': 36, 'CAA': 37, 'CAG': 38, 'AAT': 39, 'AAC': 40, 'AAA': 41, 'AAG': 42, 'GAT': 43, 'GAC': 44, 'GAA': 45, 'GAG': 46, 'TGT': 47, 'TGC': 48, 'TGG': 49, 'CGT': 50, 'CGC': 51, 'CGA': 52, 'CGG': 53, 'AGT': 54, 'AGC': 55, 'AGA': 56, 'AGG': 57, 'GGT': 58, 'GGC': 59, 'GGA': 60, 'GGG': 61
}

def encode_sequences_rna(sequences, codon_index):
    all_codon_indices = []
    for sequence in sequences:
        codon_indices = []
        for i in range(0, len(sequence), 3):
            codon = sequence[i:i+3]
            if len(codon) == 3:
                if set(codon).issubset(set('ATCG')):
                    codon_indices.append(codon_index[codon])
                else:
                    raise ValueError('Invalid nucleotide character in sequence: {}'.format(codon))
        all_codon_indices.append(codon_indices)
    return all_codon_indices


train_sequences_rna = encode_sequences_rna(seq_train, codon_index)
val_sequences_rna = encode_sequences_rna(seq_val, codon_index)
test_sequences_rna = encode_sequences_rna(seq_test, codon_index)

seq_train[0]

print(train_sequences_rna[0])

min_length_rna, max_length_rna, median_length_rna = length(train_sequences_rna)
print("Taille Maximale des séquences : ", max_length_rna)

train_padded_arn = pad_sequences(train_sequences_rna, maxlen=(max_length_rna), padding="post", truncating="post")
val_padded_arn = pad_sequences(val_sequences_rna, maxlen=(max_length_rna), padding="post", truncating="post")
test_padded_arn = pad_sequences(test_sequences_rna, maxlen=(max_length_rna), padding="post", truncating="post")

print("Training   : ", train_padded_arn.shape)
print("Validation : ", val_padded_arn.shape)
print("Test       : ", test_padded_arn.shape)

## Models

#### Functions

es = EarlyStopping(monitor='val_loss', patience=3, verbose=1)

class TransformerBlock(layers.Layer):
    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):
        super(TransformerBlock,self).__init__()
        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
        self.ffn = keras.Sequential(
            [layers.Dense(ff_dim, activation="relu"), layers.Dense(embed_dim),]
        )
        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)
        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)
        self.dropout1 = layers.Dropout(rate)
        self.dropout2 = layers.Dropout(rate)

    def call(self, inputs, training):
        attn_output = self.att(inputs, inputs)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(inputs + attn_output)
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        return self.layernorm2(out1 + ffn_output)

class TokenAndPositionEmbedding(layers.Layer):
    def __init__(self, maxlen, vocab_size, embed_dim):
        super(TokenAndPositionEmbedding, self).__init__()
        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)
        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)

    def call(self, x):
        maxlen = tf.shape(x)[-1]
        positions = tf.range(start=0, limit=maxlen, delta=1)
        positions = self.pos_emb(positions)
        x = self.token_emb(x)
        return x + positions

### Proteins

#### Bi-LSTM

##### The Model

x_input = Input(shape=(max_length_pro,), name="Input_Layer")

emb = Embedding(len(aa_alphabet), 100, input_length=max_length_pro, name="Embedding_Layer")(x_input)
bi_rnn = Bidirectional(LSTM(50), name="Bidirectional_LSTM_Layer")(emb)
x = Dropout(0.1, name="Dropout_Layer_1")(bi_rnn)
x = Dense(100, activation='relu', name="Dense_Layer_1")(x)
x = Dense(100, activation='relu', name="Dense_Layer_2")(x)

x_output = Dense(3, activation='softmax', name="Softmax_Layer_1")(x)
model_lstm_pro = Model(inputs=x_input, outputs=x_output)

model_lstm_pro.compile("adam", "binary_crossentropy", metrics=["accuracy"])
model_lstm_pro.summary()

##### Training

history_lstm_pro = model_lstm_pro.fit(
  train_padded_pro, train_labels,
  epochs=50, batch_size=32,
  validation_data=(val_padded_pro, val_labels),
  callbacks=[es]
  )

##### Plot History

plt.plot(history_lstm_pro.history['accuracy'])
plt.plot(history_lstm_pro.history['val_accuracy'])
plt.plot(history_lstm_pro.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(history_lstm_pro.history['loss'])
plt.plot(history_lstm_pro.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

##### Evaluation

results_lstm_train_pro = model_lstm_pro.evaluate(train_padded_pro, train_labels, batch_size=32)
results_lstm_val_pro = model_lstm_pro.evaluate(val_padded_pro, val_labels, batch_size=32)
results_lstm_test_pro = model_lstm_pro.evaluate(test_padded_pro, test_labels, batch_size=32)

##### Save Model

model_lstm_pro.save('/content/drive/MyDrive/Nissrine/Misclassified/Proteines_Bi-LSTM')

#### Transformers

##### The Model

embed_dim = 100  
num_heads = 2  
ff_dim = 50 

inputs = layers.Input(shape=(max_length_pro,), name="Input_Layer")
embedding_layer = TokenAndPositionEmbedding(max_length_pro, len(aa_alphabet), embed_dim)
x = embedding_layer(inputs)

transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)
x = transformer_block(x)

x = layers.GlobalAveragePooling1D(name="GlobalAveragePooling1D_Layer")(x)
x = layers.Dropout(0.1, name="Dropout_Layer_1")(x)

x = layers.Dense(100, activation="relu", name="Dense_Layer_1")(x)
x = layers.Dropout(0.1, name="Dropout_Layer_2")(x)

x = layers.Dense(100, activation="relu", name="Dense_Layer_2")(x)
x = layers.Dropout(0.1, name="Dropout_Layer_3")(x)

outputs = layers.Dense(3, activation="softmax", name="Softmax_Layer_1")(x)

model_trans_pro = keras.Model(inputs=inputs, outputs=outputs)

model_trans_pro.compile("adam", "binary_crossentropy", metrics=["accuracy"])
model_trans_pro.summary()

##### Training

history_trans_pro = model_trans_pro.fit(
  train_padded_pro, train_labels,
  epochs=50, batch_size=32,
  validation_data=(val_padded_pro, val_labels),
  callbacks=[es]
  )

##### Plot History

plt.plot(history_trans_pro.history['accuracy'])
plt.plot(history_trans_pro.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(history_trans_pro.history['loss'])
plt.plot(history_trans_pro.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

##### Evaluation

results_trans_train_pro = model_trans_pro.evaluate(train_padded_pro, train_labels, batch_size=32)
results_trans_val_pro = model_trans_pro.evaluate(val_padded_pro, val_labels, batch_size=32)
results_trans_test_pro = model_trans_pro.evaluate(test_padded_pro, test_labels, batch_size=32)

##### Save Model

model_trans_pro.save('/content/drive/MyDrive/Nissrine/Misclassified/Proteines_Transformers')

### ARN

#### Bi-LSTM

##### The Model

x_input = Input(shape=(max_length_rna,), name="Input_Layer")

emb = Embedding(len(codon_index), 100, input_length=max_length, name="Embedding_Layer")(x_input)
bi_rnn = Bidirectional(LSTM(50), name="Bidirectional_LSTM_Layer")(emb)
x = Dropout(0.1, name="Dropout_Layer_1")(bi_rnn)
x = Dense(100, activation='relu', name="Dense_Layer_1")(x)
x = Dense(100, activation='relu', name="Dense_Layer_2")(x)

x_output = Dense(3, activation='softmax', name="Softmax_Layer_1")(x)
model_lstm_arn = Model(inputs=x_input, outputs=x_output)

model_lstm_arn.compile("adam", "binary_crossentropy", metrics=["accuracy"])
model_lstm_arn.summary()

##### Training

history_lstm_arn = model_lstm_arn.fit(
  train_padded_arn, train_labels,
  epochs=50, batch_size=32,
  validation_data=(val_padded_arn, val_labels),
  callbacks=[es]
  )

##### Plot History

print(history_lstm_arn.history.keys())

plt.plot(history_lstm_arn.history['accuracy'])
plt.plot(history_lstm_arn.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(history_lstm_arn.history['loss'])
plt.plot(history_lstm_arn.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

##### Evaluation

results_lstm_train_arn = model_lstm_arn.evaluate(train_padded_arn, train_labels, batch_size=32)
results_lstm_val_arn = model_lstm_arn.evaluate(val_padded_arn, val_labels, batch_size=32)
results_lstm_test_arn = model_lstm_arn.evaluate(test_padded_arn, test_labels, batch_size=32)

##### Save Model

model_lstm_arn.save('/content/drive/MyDrive/Nissrine/Misclassified/ARN_Bi-LSTM')

#### Transformers

##### The Model

embed_dim = 100  
num_heads = 2  
ff_dim = 50  

inputs = layers.Input(shape=(max_length_rna,), name="Input_Layer")
embedding_layer = TokenAndPositionEmbedding(max_length_rna, len(codon_index), embed_dim)
x = embedding_layer(inputs)

transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)
x = transformer_block(x)

x = layers.GlobalAveragePooling1D(name="GlobalAveragePooling1D_Layer")(x)
x = layers.Dropout(0.1, name="Dropout_Layer_1")(x)

x = layers.Dense(100, activation="relu", name="Dense_Layer_1")(x)
x = layers.Dropout(0.1, name="Dropout_Layer_2")(x)

x = layers.Dense(100, activation="relu", name="Dense_Layer_2")(x)
x = layers.Dropout(0.1, name="Dropout_Layer_3")(x)

outputs = layers.Dense(3, activation="softmax", name="Softmax_Layer_1")(x)

model_trans_arn = keras.Model(inputs=inputs, outputs=outputs)

model_trans_arn.compile("adam", "binary_crossentropy", metrics=["accuracy"])
model_trans_arn.summary()

##### Training

history_trans_arn = model_trans_arn.fit(
  train_padded_arn, train_labels,
  epochs=50, batch_size=32,
  validation_data=(val_padded_arn, val_labels),
  callbacks=[es]
  )

##### Plot History

print(history_trans_arn.history.keys())

plt.plot(history_trans_arn.history['accuracy'])
plt.plot(history_trans_arn.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(history_trans_arn.history['loss'])
plt.plot(history_trans_arn.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

##### Evaluation

results_trans_train_arn = model_trans_arn.evaluate(train_padded_arn, train_labels, batch_size=32)
results_trans_val_arn = model_trans_arn.evaluate(val_padded_arn, val_labels, batch_size=32)
results_trans_test_arn = model_trans_arn.evaluate(test_padded_arn, test_labels, batch_size=32)

##### Save Model

model_trans_arn.save('/content/drive/MyDrive/Nissrine/Misclassified/ARN_Transformers')

## Latent Space Visualization

test_set = pd.read_excel('/content/drive/MyDrive/Misclassified/Data/Train_Val_Test/test_df.xlsx')
model_arn_lstm = keras.models.load_model('/content/drive/MyDrive/Misclassified/Notebooks/Saved_models/ARN_Bi-LSTM')

### Open Reading Frame

def codonStart(X,y):
  seq = X
  host = y.to_list()

  N = []
  X_ = []
  y_ = []

  numero = 0
  numbis = 0
  for i in range(len(seq)):
    seq_ = seq[i]
    host_ = host[i]

    numero = 0
    numbis = 0
    while numero < len(seq_)-2:
        if seq_[numero:numero+3] == 'ATG':
            numbis = numero
            N.append(numbis)
            X_.append(seq_)
            y_.append(host_)

            break
        numero += 1
  return (X_, y_, N)

X_test, y_test, idxStart_test = codonStart(test_set.Sequence, test_set.Host)

nonStop = ['GCT', 'GCC', 'GCA', 'GCG', 'CGT', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG', 'AAT', 'AAC', 'GAT', 'GAC', 'TGT', 'TGC', 'CAA', 'CAG', 'GAA', 'GAG', 'GGT', 'GGC', 'GGA', 'GGG', 'CAT', 'CAC', 'ATT', 'ATC', 'ATA', 'TTA', 'TTG', 'CTT', 'CTC', 'CTA', 'CTG', 'AAA', 'AAG', 'ATG', 'TTT', 'TTC', 'CCT', 'CCC', 'CCA', 'CCG', 'TCT', 'TCC', 'TCA', 'TCG', 'AGT', 'AGC', 'ACT', 'ACC', 'ACA', 'ACG', 'TGG', 'TAT', 'TAC', 'GTT', 'GTC', 'GTA', 'GTG']
stop = ['TAG', 'TGA', 'TAA']

def toSeq(X, N):
  seq_ = []
  tmp = []
  for i in range(len(X)):
    seq = X[i]
    numbis = N[i]
    while numbis < len(seq)-2:
      if seq[numbis:numbis+3] in nonStop:
        tmp += seq[numbis:numbis+3]
      elif seq[numbis:numbis+3] in stop:
        break

      numbis += 3
    str = ""
    seq_.append(str.join(tmp))
    tmp=[]

  return(seq_)

seq_test = toSeq(X_test, idxStart_test)

### Length

def length(data):
  length = []
  for i in range(len(data)):
    length.append(len(data[i]))

  min = int(np.min(length))
  max = int(np.max(length))
  median = int(np.median(length))

  return (min, max, median)

min_length, max_length, median_length = length(seq_test)

print("Taille Minimale des séquences : ", min_length)
print("Taille Maximale des séquences : ", max_length)

### Labels

le = LabelEncoder()

test_labels = le.fit_transform(y_test)
test_labels = to_categorical(test_labels)

print("Test: ", test_labels.shape)

### RNA

codon_index = {
    'TTT': 1, 'TTC': 2, 'TTA': 3, 'TTG': 4, 'CTT': 5, 'CTC': 6, 'CTA': 7, 'CTG': 8, 'ATT': 9, 'ATC': 10, 'ATA': 11, 'ATG': 12, 'GTT': 13, 'GTC': 14, 'GTA': 15, 'GTG': 16, 'TCT': 17, 'TCC': 18, 'TCA': 19, 'TCG': 20, 'CCT': 21, 'CCC': 22, 'CCA': 23, 'CCG': 24, 'ACT': 25, 'ACC': 26, 'ACA': 27, 'ACG': 28, 'GCT': 29, 'GCC': 30, 'GCA': 31, 'GCG': 32, 'TAT': 33, 'TAC': 34, 'CAT': 35, 'CAC': 36, 'CAA': 37, 'CAG': 38, 'AAT': 39, 'AAC': 40, 'AAA': 41, 'AAG': 42, 'GAT': 43, 'GAC': 44, 'GAA': 45, 'GAG': 46, 'TGT': 47, 'TGC': 48, 'TGG': 49, 'CGT': 50, 'CGC': 51, 'CGA': 52, 'CGG': 53, 'AGT': 54, 'AGC': 55, 'AGA': 56, 'AGG': 57, 'GGT': 58, 'GGC': 59, 'GGA': 60, 'GGG': 61
}

def encode_sequences_rna(sequences, codon_index):
    all_codon_indices = []
    for sequence in sequences:
        codon_indices = []
        for i in range(0, len(sequence), 3):
            codon = sequence[i:i+3]
            if len(codon) == 3:
                if set(codon).issubset(set('ATCG')):
                    codon_indices.append(codon_index[codon])
                else:
                    raise ValueError('Invalid nucleotide character in sequence: {}'.format(codon))
        all_codon_indices.append(codon_indices)
    return all_codon_indices


test_sequences_rna = encode_sequences_rna(seq_test, codon_index)
print(test_sequences_rna[0])

min_length_rna, max_length_rna, median_length_rna = length(test_sequences_rna)
print("Taille Maximale des séquences : ", max_length_rna)

max_length_rna=770
test_padded_arn = pad_sequences(test_sequences_rna, maxlen=(max_length_rna), padding="post", truncating="post")

print("Test: ", test_padded_arn.shape)

### Predictions


model_arn_lstm.summary()

test_loss, test_accuracy = model_arn_lstm.evaluate(test_padded_arn, test_labels, batch_size=32)
print("Test Loss:", test_loss)
print("Test Accuracy:", test_accuracy)

arn_lstm = model_arn_lstm.predict(test_padded_arn, batch_size=32)

def getResultsARN(y_test, X_test, predictions):

  tiers = []
  pred_class = []
  pred_max = []
  pred_avian = []
  pred_human = []
  pred_swine = []
  seq_arn = []
  host = []

  for i in range(len(y_test)):
    host.append(y_test[i])
  i=0
  for i in range(len(X_test)):
    seq_arn.append(X_test[i])  
  i=0 
  for i in range(len(predictions)):
    pred = predictions[i]

    av = pred[0]
    hu = pred[1]
    sw = pred[2]
    pred_avian.append(av.round(3))
    pred_human.append(hu.round(3))
    pred_swine.append(sw.round(3))

    max = pred.max()
    pred_max.append(max.round(3))

    if (max == av):
      classe = 'Avian'
    elif (max == hu):
      classe = 'Human'
    elif (max == sw):
      classe = 'Swine'
    pred_class.append(classe)

    if (max >=0.95 and max <=1):
      tier = '[95-100]'
    elif (max >=0.90 and max <0.95):
      tier = '[90-95]'
    elif (max >=0.85 and max <0.90):
      tier = '[85-90]'
    elif (max >=0.80 and max <0.85):
      tier = '[80-85]'
    elif (max >=0.75 and max <0.80):
      tier = '[75-80]'
    elif (max >=0.70 and max <0.75):
      tier = '[70-75]'
    elif (max >=0.65 and max <0.70):
      tier = '[65-70]'
    elif (max >=0.60 and max <0.65):
      tier = '[60-65]'
    elif (max >=0.55 and max <0.60):
      tier = '[55-60]'
    elif (max >=0.50 and max <0.55):
      tier = '[50-55]'      
    elif (max >=0.45 and max <0.50):
      tier = '[45-50]'
    elif (max >=0.40 and max <0.45):
      tier = '[40-45]'   
    elif (max >=0.35 and max <0.40):
      tier = '[35-40]'  
    elif (max >=0.30 and max <0.35):
      tier = '[30-35]' 

    tiers.append(tier)

  return(tiers, pred_class, pred_max, pred_avian, pred_human, pred_swine, seq_arn, host)

def toDataframesARN(tiers, pred_class, pred_max, pred_avian, pred_human, pred_swine, seq_arn, host):

  df = pd.DataFrame(columns=['tiers', 'pred_class', 'pred_max', 'pred_avian', 'pred_human', 'pred_swine', 'seq_arn', 'host'])
  df['tiers'] = tiers
  df['pred_class'] = pred_class
  df['pred_max'] = pred_max
  df['pred_avian'] = pred_avian
  df['pred_human'] = pred_human
  df['pred_swine'] = pred_swine
  df['seq_arn'] = seq_arn
  df['host'] = host

  return(df)

tiers_lstm_arn, pred_class_lstm_arn, pred_max_lstm_arn, pred_avian_lstm_arn, pred_human_lstm_arn, pred_swine_lstm_arn, seq_arn_lstm_arn, host_lstm_arn = getResultsARN(y_test, X_test, arn_lstm)

df_test_arn_lstm = toDataframesARN(tiers_lstm_arn, pred_class_lstm_arn, pred_max_lstm_arn, pred_avian_lstm_arn, pred_human_lstm_arn, pred_swine_lstm_arn, seq_arn_lstm_arn, host_lstm_arn)

df_test_arn_lstm

df=test_set
df= df.drop("Accession", axis=1)
df= df.drop("Host", axis=1)
df= df.drop("Sequence", axis=1)

df

result = pd.concat([df, df_test_arn_lstm], axis=1).reindex(df_test_arn_lstm.index)
result

result.to_excel('/content/drive/MyDrive/Misclassified/Notebooks/df_test_arn_lstm.xlsx')

### Latent Space

latent_space_model = tf.keras.models.Model(inputs=model_arn_lstm.input, outputs=model_arn_lstm.layers[-1].output)

latent_space = latent_space_model.predict(test_padded_arn, batch_size=32)

print("Taille de l'espace latent avant réduction : ", latent_space.shape)

mapper_rna = umap.UMAP(n_neighbors=15, min_dist=0.8, n_components=2, metric='canberra', random_state=42).fit(latent_space)

hover_data_rna = pd.DataFrame({'index':np.arange(len(result)),'tiers':result['tiers'], 'host':result['host'], 'pred_class':result['pred_class']})
p_rna = umap.plot.interactive(mapper_rna, labels=result['pred_class'], hover_data=hover_data_rna,color_key_cmap='prism', point_size=3)
output_notebook()
show(p_rna)

hover_data_rna = pd.DataFrame({'index':np.arange(len(result)),'tiers':result['tiers'], 'host':result['host'], 'pred_class':result['pred_class']})
p_rna = umap.plot.interactive(mapper_rna, labels=result['tiers'], hover_data=hover_data_rna,color_key_cmap='ocean', point_size=2.5)
output_notebook()
show(p_rna)

### K-means

X_rna=mapper_rna.embedding_
X_rna

from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=3)
kmeans.fit(X_rna)
y_kmeans_rna = kmeans.predict(X_rna)

df=result
avian_indices = df[(df['pred_class'] == 'Avian') & (df['host'] == 'Avian')].index[:1000]
human_indices = df[(df['pred_class'] == 'Human') & (df['host'] == 'Human')].index[:1000]
swine_indices = df[(df['pred_class'] == 'Swine') & (df['host'] == 'Swine')].index[:1000]

##### Avian

plt.scatter(X_rna[:, 0], X_rna[:, 1], c=y_kmeans_rna, s=10, cmap='viridis')

centers_rna = kmeans.cluster_centers_
plt.scatter(centers_rna[:, 0], centers_rna[:, 1], c='black', s=200, alpha=0.5);
for i in avian_indices:
  plt.scatter(X_rna[i, 0], X_rna[i, 1], s=10)

centers_rna

import numpy as np
dist=[]
for i in avian_indices:
  for j in range(len(centers_rna)):
    dist.append(np.linalg.norm(centers_rna[j] - X_rna[i]))
#print(dist)
shape = (len(avian_indices),len(centers_rna))
dist_avian = np.array(dist)
dist_avian.reshape(shape)


dist_df_avian = pd.DataFrame(dist_avian.reshape(shape), columns = ['distHuman','distAvian','distSwine'])
dist_df_avian

dist_df_avian.to_excel('/content/drive/MyDrive/Misclassified/Notebooks/kmeans_dist_euc/dist_df_avian.xlsx')

##### Human

plt.scatter(X_rna[:, 0], X_rna[:, 1], c=y_kmeans_rna, s=10, cmap='viridis')

centers_rna = kmeans.cluster_centers_
plt.scatter(centers_rna[:, 0], centers_rna[:, 1], c='black', s=200, alpha=0.5);
for i in human_indices:
  plt.scatter(X_rna[i, 0], X_rna[i, 1], s=10)

centers_rna

import numpy as np
dist=[]
for i in human_indices:
  for j in range(len(centers_rna)):
    dist.append(np.linalg.norm(centers_rna[j] - X_rna[i]))
#print(dist)
shape = (len(human_indices),len(centers_rna))
dist_human= np.array(dist)
dist_human.reshape(shape)


dist_df_human = pd.DataFrame(dist_human.reshape(shape), columns = ['distHuman','distAvian','distSwine'])
dist_df_human

dist_df_human = dist_df_human[['distAvian', 'distHuman', 'distSwine']]
dist_df_human.to_excel('/content/drive/MyDrive/Misclassified/Notebooks/kmeans_dist_euc/dist_df_human.xlsx')

##### Swine

plt.scatter(X_rna[:, 0], X_rna[:, 1], c=y_kmeans_rna, s=10, cmap='viridis')

centers_rna = kmeans.cluster_centers_
plt.scatter(centers_rna[:, 0], centers_rna[:, 1], c='black', s=200, alpha=0.5);
for i in swine_indices:
  plt.scatter(X_rna[i, 0], X_rna[i, 1], s=10)

centers_rna

import numpy as np
dist=[]
for i in swine_indices:
  for j in range(len(centers_rna)):
    dist.append(np.linalg.norm(centers_rna[j] - X_rna[i]))
#print(dist)
shape = (len(swine_indices),len(centers_rna))
dist_swine= np.array(dist)
dist_swine.reshape(shape)


dist_df_swine = pd.DataFrame(dist_swine.reshape(shape), columns = ['distHuman','distAvian','distSwine'])
dist_df_swine

dist_df_swine = dist_df_swine[['distAvian', 'distHuman', 'distSwine']]
dist_df_swine.to_excel('/content/drive/MyDrive/Misclassified/Notebooks/kmeans_dist_euc/dist_df_swine.xlsx')

## Test set augmentation 

test_df = pd.read_excel('/content/drive/MyDrive/Misclassified/Data/Testset_augmentation/test_df.xlsx')
discarded_seq_df = pd.read_excel('/content/drive/MyDrive/Misclassified/Data/Testset_augmentation/discarded_seq_df.xlsx')

test_set = pd.concat([test_df, discarded_seq_df])

test_set.to_excel('/content/drive/MyDrive/Misclassified/Data/Testset_augmentation/test_set.xlsx', index=False)

test_set = pd.read_excel('/content/drive/MyDrive/Misclassified/Data/Testset_augmentation/test_set.xlsx')
model_arn_lstm = keras.models.load_model('/content/drive/MyDrive/Misclassified/Notebooks/Saved_models/ARN_Bi-LSTM')

### Open Reading Frame

def codonStart(X,y):
  seq = X
  host = y.to_list()

  N = []
  X_ = []
  y_ = []

  numero = 0
  numbis = 0
  for i in range(len(seq)):
    seq_ = seq[i]
    host_ = host[i]

    numero = 0
    numbis = 0
    while numero < len(seq_)-2:
        if seq_[numero:numero+3] == 'ATG':
            numbis = numero
            N.append(numbis)
            X_.append(seq_)
            y_.append(host_)

            break
        numero += 1
  return (X_, y_, N)

X_test, y_test, idxStart_test = codonStart(test_set.Sequence, test_set.Host)

nonStop = ['GCT', 'GCC', 'GCA', 'GCG', 'CGT', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG', 'AAT', 'AAC', 'GAT', 'GAC', 'TGT', 'TGC', 'CAA', 'CAG', 'GAA', 'GAG', 'GGT', 'GGC', 'GGA', 'GGG', 'CAT', 'CAC', 'ATT', 'ATC', 'ATA', 'TTA', 'TTG', 'CTT', 'CTC', 'CTA', 'CTG', 'AAA', 'AAG', 'ATG', 'TTT', 'TTC', 'CCT', 'CCC', 'CCA', 'CCG', 'TCT', 'TCC', 'TCA', 'TCG', 'AGT', 'AGC', 'ACT', 'ACC', 'ACA', 'ACG', 'TGG', 'TAT', 'TAC', 'GTT', 'GTC', 'GTA', 'GTG']
stop = ['TAG', 'TGA', 'TAA']

def toSeq(X, N):
  seq_ = []
  tmp = []
  for i in range(len(X)):
    seq = X[i]
    numbis = N[i]
    while numbis < len(seq)-2:
      if seq[numbis:numbis+3] in nonStop:
        tmp += seq[numbis:numbis+3]
      elif seq[numbis:numbis+3] in stop:
        break

      numbis += 3
    str = ""
    seq_.append(str.join(tmp))
    tmp=[]

  return(seq_)

seq_test = toSeq(X_test, idxStart_test)

### Length

def length(data):
  length = []
  for i in range(len(data)):
    length.append(len(data[i]))

  min = int(np.min(length))
  max = int(np.max(length))
  median = int(np.median(length))

  return (min, max, median)

min_length, max_length, median_length = length(seq_test)

print("Taille Minimale des séquences : ", min_length)
print("Taille Maximale des séquences : ", max_length)

### Labels

le = LabelEncoder()

test_labels = le.fit_transform(y_test)
test_labels = to_categorical(test_labels)

print("Test: ", test_labels.shape)

### RNA

codon_index = {
    'TTT': 1, 'TTC': 2, 'TTA': 3, 'TTG': 4, 'CTT': 5, 'CTC': 6, 'CTA': 7, 'CTG': 8, 'ATT': 9, 'ATC': 10, 'ATA': 11, 'ATG': 12, 'GTT': 13, 'GTC': 14, 'GTA': 15, 'GTG': 16, 'TCT': 17, 'TCC': 18, 'TCA': 19, 'TCG': 20, 'CCT': 21, 'CCC': 22, 'CCA': 23, 'CCG': 24, 'ACT': 25, 'ACC': 26, 'ACA': 27, 'ACG': 28, 'GCT': 29, 'GCC': 30, 'GCA': 31, 'GCG': 32, 'TAT': 33, 'TAC': 34, 'CAT': 35, 'CAC': 36, 'CAA': 37, 'CAG': 38, 'AAT': 39, 'AAC': 40, 'AAA': 41, 'AAG': 42, 'GAT': 43, 'GAC': 44, 'GAA': 45, 'GAG': 46, 'TGT': 47, 'TGC': 48, 'TGG': 49, 'CGT': 50, 'CGC': 51, 'CGA': 52, 'CGG': 53, 'AGT': 54, 'AGC': 55, 'AGA': 56, 'AGG': 57, 'GGT': 58, 'GGC': 59, 'GGA': 60, 'GGG': 61
}

def encode_sequences_rna(sequences, codon_index):
    all_codon_indices = []
    for sequence in sequences:
        codon_indices = []
        for i in range(0, len(sequence), 3):
            codon = sequence[i:i+3]
            if len(codon) == 3:
                if set(codon).issubset(set('ATCG')):
                    codon_indices.append(codon_index[codon])
                else:
                    raise ValueError('Invalid nucleotide character in sequence: {}'.format(codon))
        all_codon_indices.append(codon_indices)
    return all_codon_indices


test_sequences_rna = encode_sequences_rna(seq_test, codon_index)
print(test_sequences_rna[0])

min_length_rna, max_length_rna, median_length_rna = length(test_sequences_rna)
print("Taille Maximale des séquences : ", max_length_rna)

max_length_rna=770
test_padded_arn = pad_sequences(test_sequences_rna, maxlen=(max_length_rna), padding="post", truncating="post")

print("Test: ", test_padded_arn.shape)

### Predictions


model_arn_lstm.summary()

test_loss, test_accuracy = model_arn_lstm.evaluate(test_padded_arn, test_labels, batch_size=32)
print("Test Loss:", test_loss)
print("Test Accuracy:", test_accuracy)

arn_lstm = model_arn_lstm.predict(test_padded_arn, batch_size=32)

def getResultsARN(y_test, X_test, predictions):

  tiers = []
  pred_class = []
  pred_max = []
  pred_avian = []
  pred_human = []
  pred_swine = []
  seq_arn = []
  host = []

  for i in range(len(y_test)):
    host.append(y_test[i])
  i=0
  for i in range(len(X_test)):
    seq_arn.append(X_test[i])  
  i=0 
  for i in range(len(predictions)):
    pred = predictions[i]

    av = pred[0]
    hu = pred[1]
    sw = pred[2]
    pred_avian.append(av.round(3))
    pred_human.append(hu.round(3))
    pred_swine.append(sw.round(3))

    max = pred.max()
    pred_max.append(max.round(3))

    if (max == av):
      classe = 'Avian'
    elif (max == hu):
      classe = 'Human'
    elif (max == sw):
      classe = 'Swine'
    pred_class.append(classe)

    if (max >=0.95 and max <=1):
      tier = '[95-100]'
    elif (max >=0.90 and max <0.95):
      tier = '[90-95]'
    elif (max >=0.85 and max <0.90):
      tier = '[85-90]'
    elif (max >=0.80 and max <0.85):
      tier = '[80-85]'
    elif (max >=0.75 and max <0.80):
      tier = '[75-80]'
    elif (max >=0.70 and max <0.75):
      tier = '[70-75]'
    elif (max >=0.65 and max <0.70):
      tier = '[65-70]'
    elif (max >=0.60 and max <0.65):
      tier = '[60-65]'
    elif (max >=0.55 and max <0.60):
      tier = '[55-60]'
    elif (max >=0.50 and max <0.55):
      tier = '[50-55]'      
    elif (max >=0.45 and max <0.50):
      tier = '[45-50]'
    elif (max >=0.40 and max <0.45):
      tier = '[40-45]'   
    elif (max >=0.35 and max <0.40):
      tier = '[35-40]'  
    elif (max >=0.30 and max <0.35):
      tier = '[30-35]' 

    tiers.append(tier)

  return(tiers, pred_class, pred_max, pred_avian, pred_human, pred_swine, seq_arn, host)

def toDataframesARN(tiers, pred_class, pred_max, pred_avian, pred_human, pred_swine, seq_arn, host):

  df = pd.DataFrame(columns=['tiers', 'pred_class', 'pred_max', 'pred_avian', 'pred_human', 'pred_swine', 'seq_arn', 'host'])
  df['tiers'] = tiers
  df['pred_class'] = pred_class
  df['pred_max'] = pred_max
  df['pred_avian'] = pred_avian
  df['pred_human'] = pred_human
  df['pred_swine'] = pred_swine
  df['seq_arn'] = seq_arn
  df['host'] = host

  return(df)

tiers_lstm_arn, pred_class_lstm_arn, pred_max_lstm_arn, pred_avian_lstm_arn, pred_human_lstm_arn, pred_swine_lstm_arn, seq_arn_lstm_arn, host_lstm_arn = getResultsARN(y_test, X_test, arn_lstm)

df_arn_lstm = toDataframesARN(tiers_lstm_arn, pred_class_lstm_arn, pred_max_lstm_arn, pred_avian_lstm_arn, pred_human_lstm_arn, pred_swine_lstm_arn, seq_arn_lstm_arn, host_lstm_arn)

df_arn_lstm

df=test_set
df= df.drop("Accession", axis=1)
df= df.drop("Host", axis=1)
df= df.drop("Sequence", axis=1)

df

result = pd.concat([df, df_arn_lstm], axis=1).reindex(df_arn_lstm.index)
result

result.to_excel('/content/drive/MyDrive/Misclassified/Notebooks/df_arn_lstm.xlsx')

## Well/Misclassified Sequences

df_arn_lstm = pd.read_excel('/content/drive/MyDrive/Misclassified/Notebooks/df_arn_lstm.xlsx')

df_arn_lstm.head()

def groundTruth(data):
  
  x = (data['host']=='Avian') 
  y = (data['host']=='Human') 
  z = (data['host']=='Swine') 

  return(len(data[x]), len(data[y]), len(data[z]))

def predictions(data):
  
  a = (data['pred_class']=='Avian') 
  b = (data['pred_class']=='Human') 
  c = (data['pred_class']=='Swine') 

  return(len(data[a]), len(data[b]), len(data[c]))

def avian(data):
  
  avian_sur = (data['host']=='Avian') & (data['pred_class']=='Avian') 
  avian_ambigu = (data['host']=='Avian') & (data['pred_class']!='Avian') 
  avian_human = (data['host']=='Avian') & (data['pred_class']=='Human') 
  avian_swine = (data['host']=='Avian') & (data['pred_class']=='Swine') 

  return(avian_sur, avian_ambigu, avian_human, avian_swine)

def human(data):

  human_sur = (data['host']=='Human') & (data['pred_class']=='Human') 
  human_ambigu = (data['host']=='Human') & (data['pred_class']!='Human') 
  human_avian = (data['host']=='Human') & (data['pred_class']=='Avian') 
  human_swine = (data['host']=='Human') & (data['pred_class']=='Swine') 

  return(human_sur, human_ambigu, human_avian, human_swine)

def swine(data):

  swine_sur = (data['host']=='Swine') & (data['pred_class']=='Swine') 
  swine_ambigu = (data['host']=='Swine') & (data['pred_class']!='Swine') 
  swine_avian = (data['host']=='Swine') & (data['pred_class']=='Avian') 
  swine_human = (data['host']=='Swine') & (data['pred_class']=='Human') 

  return(swine_sur, swine_ambigu, swine_avian, swine_human)

x, y, z = groundTruth(df_arn_lstm)
a, b, c = predictions(df_arn_lstm)

avian_sur_arn_lstm, avian_ambigu_arn_lstm, avian_human_arn_lstm, avian_swine_arn_lstm = avian(df_arn_lstm)
human_sur_arn_lstm, human_ambigu_arn_lstm, human_avian_arn_lstm, human_swine_arn_lstm = human(df_arn_lstm)
swine_sur_arn_lstm, swine_ambigu_arn_lstm, swine_avian_arn_lstm, swine_human_arn_lstm = swine(df_arn_lstm)

def plot_avian(data, avian_sur, avian_human, avian_swine):
  labels = 'avian_sur','avian_human','avian_swine'
  sizes = [len(data[avian_sur]), len(data[avian_human]), len(data[avian_swine])]
  explode = (0, 0.1, 0.2)  

  fig1, ax1 = plt.subplots()
  ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=False, startangle=90)
  ax1.axis('equal') 

  plt.show()

def plot_human(data, human_sur, human_avian, human_swine):
  labels = 'human_sur','human_avian','human_swine'
  sizes = [len(data[human_sur]), len(data[human_avian]), len(data[human_swine])]
  explode = (0, 0.1, 0.2)  

  fig1, ax1 = plt.subplots()
  ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=False, startangle=90)
  ax1.axis('equal') 

  plt.show()

def plot_swine(data, swine_sur, swine_avian, swine_human):
  labels = 'swine_sur','swine_avian','swine_human'
  sizes = [len(data[swine_sur]), len(data[swine_avian]), len(data[swine_human])]
  explode = (0, 0.1, 0.2)  

  fig1, ax1 = plt.subplots()
  ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=False, startangle=90)
  ax1.axis('equal') 

  plt.show()

plot_avian(df_arn_lstm, avian_sur_arn_lstm, avian_human_arn_lstm, avian_swine_arn_lstm)

plot_human(df_arn_lstm, human_sur_arn_lstm, human_avian_arn_lstm, human_swine_arn_lstm)

plot_swine(df_arn_lstm, swine_sur_arn_lstm, swine_avian_arn_lstm, swine_human_arn_lstm)

## ZT well/misclassified

### H1N1_2009

#### H1N1_2009 & test_set

zoonotic_seq_1 = pd.read_excel('/content/drive/MyDrive/Nissrine/misclassified/H1N1_2009.xlsx')
zoonotic_seq_1['Gene'].fillna('NA', inplace=True)

zoonotic_seq_1['Host']='Swine'
zoonotic_seq_1['State']='New'

zoonotic_seq_1 = zoonotic_seq_1.drop('Virus_Name', axis=1)
zoonotic_seq_1 = zoonotic_seq_1.drop('Taxonomy', axis=1)
zoonotic_seq_1 = zoonotic_seq_1.drop('Detected_in', axis=1)
zoonotic_seq_1 = zoonotic_seq_1.drop('Reference', axis=1)

column_names = test_set.columns

zoonotic_seq_1 = zoonotic_seq_1.reindex(columns=column_names)
zoonotic_seq_1.head()

len(zoonotic_seq_1)

#### Open Reading Frame

def codonStart(X,y):
  seq = X
  host = y.to_list()

  N = []
  X_ = []
  y_ = []

  numero = 0
  numbis = 0
  for i in range(len(seq)):
    seq_ = seq[i]
    host_ = host[i]

    numero = 0
    numbis = 0
    while numero < len(seq_)-2:
        if seq_[numero:numero+3] == 'ATG':
            numbis = numero
            N.append(numbis)
            X_.append(seq_)
            y_.append(host_)

            break
        numero += 1
  return (X_, y_, N)

X_test, y_test, idxStart_test = codonStart(zoonotic_seq_1.Sequence, zoonotic_seq_1.Host)

nonStop = ['GCT', 'GCC', 'GCA', 'GCG', 'CGT', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG', 'AAT', 'AAC', 'GAT', 'GAC', 'TGT', 'TGC', 'CAA', 'CAG', 'GAA', 'GAG', 'GGT', 'GGC', 'GGA', 'GGG', 'CAT', 'CAC', 'ATT', 'ATC', 'ATA', 'TTA', 'TTG', 'CTT', 'CTC', 'CTA', 'CTG', 'AAA', 'AAG', 'ATG', 'TTT', 'TTC', 'CCT', 'CCC', 'CCA', 'CCG', 'TCT', 'TCC', 'TCA', 'TCG', 'AGT', 'AGC', 'ACT', 'ACC', 'ACA', 'ACG', 'TGG', 'TAT', 'TAC', 'GTT', 'GTC', 'GTA', 'GTG']
stop = ['TAG', 'TGA', 'TAA']

def toSeq(X, N):
  seq_ = []
  tmp = []
  for i in range(len(X)):
    seq = X[i]
    numbis = N[i]
    while numbis < len(seq)-2:
      if seq[numbis:numbis+3] in nonStop:
        tmp += seq[numbis:numbis+3]
      elif seq[numbis:numbis+3] in stop:
        break

      numbis += 3
    str = ""
    seq_.append(str.join(tmp))
    tmp=[]

  return(seq_)

seq_test = toSeq(X_test, idxStart_test)

#### Length

def length(data):
  length = []
  for i in range(len(data)):
    length.append(len(data[i]))

  min = int(np.min(length))
  max = int(np.max(length))
  median = int(np.median(length))

  return (min, max, median)

min_length, max_length, median_length = length(seq_test)

print("Taille Minimale des séquences : ", min_length)
print("Taille Maximale des séquences : ", max_length)

#### Labels

le = LabelEncoder()

test_labels = le.fit_transform(y_test)
test_labels = to_categorical(test_labels)

print("Test: ", test_labels.shape)

#### RNA

codon_index = {
    'TTT': 1, 'TTC': 2, 'TTA': 3, 'TTG': 4, 'CTT': 5, 'CTC': 6, 'CTA': 7, 'CTG': 8, 'ATT': 9, 'ATC': 10, 'ATA': 11, 'ATG': 12, 'GTT': 13, 'GTC': 14, 'GTA': 15, 'GTG': 16, 'TCT': 17, 'TCC': 18, 'TCA': 19, 'TCG': 20, 'CCT': 21, 'CCC': 22, 'CCA': 23, 'CCG': 24, 'ACT': 25, 'ACC': 26, 'ACA': 27, 'ACG': 28, 'GCT': 29, 'GCC': 30, 'GCA': 31, 'GCG': 32, 'TAT': 33, 'TAC': 34, 'CAT': 35, 'CAC': 36, 'CAA': 37, 'CAG': 38, 'AAT': 39, 'AAC': 40, 'AAA': 41, 'AAG': 42, 'GAT': 43, 'GAC': 44, 'GAA': 45, 'GAG': 46, 'TGT': 47, 'TGC': 48, 'TGG': 49, 'CGT': 50, 'CGC': 51, 'CGA': 52, 'CGG': 53, 'AGT': 54, 'AGC': 55, 'AGA': 56, 'AGG': 57, 'GGT': 58, 'GGC': 59, 'GGA': 60, 'GGG': 61
}

def encode_sequences_rna(sequences, codon_index):
    all_codon_indices = []
    for sequence in sequences:
        codon_indices = []
        for i in range(0, len(sequence), 3):
            codon = sequence[i:i+3]
            if len(codon) == 3:
                if set(codon).issubset(set('ATCG')):
                    codon_indices.append(codon_index[codon])
                else:
                    raise ValueError('Invalid nucleotide character in sequence: {}'.format(codon))
        all_codon_indices.append(codon_indices)
    return all_codon_indices


test_sequences_rna = encode_sequences_rna(seq_test, codon_index)
print(test_sequences_rna[0])

min_length_rna, max_length_rna, median_length_rna = length(test_sequences_rna)
print("Taille Maximale des séquences : ", max_length_rna)

max_length_rna=770
test_padded_arn = pad_sequences(test_sequences_rna, maxlen=(max_length_rna), padding="post", truncating="post")

print("Test: ", test_padded_arn.shape)

model_arn_lstm = keras.models.load_model('/content/drive/MyDrive/Nissrine/misclassified/ARN_Bi-LSTM')

zoonotic_lstm = model_arn_lstm.predict(test_padded_arn) 

def getResultsARN(y_test, X_test, predictions):

  tiers = []
  pred_class = []
  pred_max = []
  pred_avian = []
  pred_human = []
  pred_swine = []
  seq_arn = []
  host = []

  for i in range(len(y_test)):
    host.append(y_test[i])
  i=0
  for i in range(len(X_test)):
    seq_arn.append(X_test[i])  
  i=0 
  for i in range(len(predictions)):
    pred = predictions[i]

    av = pred[0]
    hu = pred[1]
    sw = pred[2]
    pred_avian.append(av.round(3))
    pred_human.append(hu.round(3))
    pred_swine.append(sw.round(3))

    max = pred.max()
    pred_max.append(max.round(3))

    if (max == av):
      classe = 'Avian'
    elif (max == hu):
      classe = 'Human'
    elif (max == sw):
      classe = 'Swine'
    pred_class.append(classe)

    if (max >=0.95 and max <=1):
      tier = '[95-100]'
    elif (max >=0.90 and max <0.95):
      tier = '[90-95]'
    elif (max >=0.85 and max <0.90):
      tier = '[85-90]'
    elif (max >=0.80 and max <0.85):
      tier = '[80-85]'
    elif (max >=0.75 and max <0.80):
      tier = '[75-80]'
    elif (max >=0.70 and max <0.75):
      tier = '[70-75]'
    elif (max >=0.65 and max <0.70):
      tier = '[65-70]'
    elif (max >=0.60 and max <0.65):
      tier = '[60-65]'
    elif (max >=0.55 and max <0.60):
      tier = '[55-60]'
    elif (max >=0.50 and max <0.55):
      tier = '[50-55]'      
    elif (max >=0.45 and max <0.50):
      tier = '[45-50]'
    elif (max >=0.40 and max <0.45):
      tier = '[40-45]'   
    elif (max >=0.35 and max <0.40):
      tier = '[35-40]'  
    elif (max >=0.30 and max <0.35):
      tier = '[30-35]' 

    tiers.append(tier)

  return(tiers, pred_class, pred_max, pred_avian, pred_human, pred_swine, seq_arn, host)

def toDataframesARN(tiers, pred_class, pred_max, pred_avian, pred_human, pred_swine, seq_arn, host):

  df = pd.DataFrame(columns=['tiers', 'pred_class', 'pred_max', 'pred_avian', 'pred_human', 'pred_swine', 'seq_arn', 'host'])
  df['tiers'] = tiers
  df['pred_class'] = pred_class
  df['pred_max'] = pred_max
  df['pred_avian'] = pred_avian
  df['pred_human'] = pred_human
  df['pred_swine'] = pred_swine
  df['seq_arn'] = seq_arn
  df['host'] = host

  return(df)

tiers_lstm_arn, pred_class_lstm_arn, pred_max_lstm_arn, pred_avian_lstm_arn, pred_human_lstm_arn, pred_swine_lstm_arn, seq_arn_lstm_arn, host_lstm_arn = getResultsARN(y_test, X_test, zoonotic_lstm)

df_zoonotic_arn_lstm = toDataframesARN(tiers_lstm_arn, pred_class_lstm_arn, pred_max_lstm_arn, pred_avian_lstm_arn, pred_human_lstm_arn, pred_swine_lstm_arn, seq_arn_lstm_arn, host_lstm_arn)

df_zoonotic_arn_lstm

#### %

import pandas as pd

df=df_zoonotic_arn_lstm
df['group'] = df.apply(lambda x: x['host'] if x['host'] == x['pred_class'] else f"{x['host']}_{x['pred_class']}", axis=1)
grouped = df.groupby('group').size().reset_index(name='count')
grouped['percentage'] = grouped['count'] / len(df) * 100

print(grouped)


### Transmission_to_Human

zoonotic_seq_2 = pd.read_excel('/content/drive/MyDrive/Misclassified/Data/Zoonotic_Viruses/Transmission_to_Human.xlsx')

zoonotic_seq_2['State']='New'
zoonotic_seq_2 = zoonotic_seq_2.rename(columns={'Origin': 'Host'})

zoonotic_seq_2 = zoonotic_seq_2.drop('Virus_Name', axis=1)
zoonotic_seq_2 = zoonotic_seq_2.drop('Virus_type', axis=1)

zoonotic_seq_2 = zoonotic_seq_2.drop('Taxon', axis=1)
zoonotic_seq_2 = zoonotic_seq_2.drop('Detected_in', axis=1)
zoonotic_seq_2 = zoonotic_seq_2.drop('Reference', axis=1)

zoonotic_seq_2.head()

df=zoonotic_seq_2
df_avian = (df[df['Host'] == 'Avian']).reset_index(drop=True)
df_swine = (df[df['Host'] == 'Swine']).reset_index(drop=True)

print(df_avian)
print(df_swine)

### Transmission_to_Human Avian

#### Open Reading Frame

def codonStart(X,y):
  seq = X
  host = y.to_list()

  N = []
  X_ = []
  y_ = []

  numero = 0
  numbis = 0
  for i in range(len(seq)):
    seq_ = seq[i]
    host_ = host[i]

    numero = 0
    numbis = 0
    while numero < len(seq_)-2:
        if seq_[numero:numero+3] == 'ATG':
            numbis = numero
            N.append(numbis)
            X_.append(seq_)
            y_.append(host_)

            break
        numero += 1
  return (X_, y_, N)

X_test, y_test, idxStart_test = codonStart(df_avian.Sequence, df_avian.Host)

nonStop = ['GCT', 'GCC', 'GCA', 'GCG', 'CGT', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG', 'AAT', 'AAC', 'GAT', 'GAC', 'TGT', 'TGC', 'CAA', 'CAG', 'GAA', 'GAG', 'GGT', 'GGC', 'GGA', 'GGG', 'CAT', 'CAC', 'ATT', 'ATC', 'ATA', 'TTA', 'TTG', 'CTT', 'CTC', 'CTA', 'CTG', 'AAA', 'AAG', 'ATG', 'TTT', 'TTC', 'CCT', 'CCC', 'CCA', 'CCG', 'TCT', 'TCC', 'TCA', 'TCG', 'AGT', 'AGC', 'ACT', 'ACC', 'ACA', 'ACG', 'TGG', 'TAT', 'TAC', 'GTT', 'GTC', 'GTA', 'GTG']
stop = ['TAG', 'TGA', 'TAA']

def toSeq(X, N):
  seq_ = []
  tmp = []
  for i in range(len(X)):
    seq = X[i]
    numbis = N[i]
    while numbis < len(seq)-2:
      if seq[numbis:numbis+3] in nonStop:
        tmp += seq[numbis:numbis+3]
      elif seq[numbis:numbis+3] in stop:
        break

      numbis += 3
    str = ""
    seq_.append(str.join(tmp))
    tmp=[]

  return(seq_)

seq_test = toSeq(X_test, idxStart_test)

#### Length

def length(data):
  length = []
  for i in range(len(data)):
    length.append(len(data[i]))

  min = int(np.min(length))
  max = int(np.max(length))
  median = int(np.median(length))

  return (min, max, median)

min_length, max_length, median_length = length(seq_test)

print("Taille Minimale des séquences : ", min_length)
print("Taille Maximale des séquences : ", max_length)

#### Labels

le = LabelEncoder()

test_labels = le.fit_transform(y_test)
test_labels = to_categorical(test_labels)

print("Test: ", test_labels.shape)

#### RNA

# Define a dictionary mapping each codon to a unique index
codon_index = {
    'TTT': 1, 'TTC': 2, 'TTA': 3, 'TTG': 4, 'CTT': 5, 'CTC': 6, 'CTA': 7, 'CTG': 8, 'ATT': 9, 'ATC': 10, 'ATA': 11, 'ATG': 12, 'GTT': 13, 'GTC': 14, 'GTA': 15, 'GTG': 16, 'TCT': 17, 'TCC': 18, 'TCA': 19, 'TCG': 20, 'CCT': 21, 'CCC': 22, 'CCA': 23, 'CCG': 24, 'ACT': 25, 'ACC': 26, 'ACA': 27, 'ACG': 28, 'GCT': 29, 'GCC': 30, 'GCA': 31, 'GCG': 32, 'TAT': 33, 'TAC': 34, 'CAT': 35, 'CAC': 36, 'CAA': 37, 'CAG': 38, 'AAT': 39, 'AAC': 40, 'AAA': 41, 'AAG': 42, 'GAT': 43, 'GAC': 44, 'GAA': 45, 'GAG': 46, 'TGT': 47, 'TGC': 48, 'TGG': 49, 'CGT': 50, 'CGC': 51, 'CGA': 52, 'CGG': 53, 'AGT': 54, 'AGC': 55, 'AGA': 56, 'AGG': 57, 'GGT': 58, 'GGC': 59, 'GGA': 60, 'GGG': 61
}

# Define a function that encodes RNA sequences using the codon index
def encode_sequences_rna(sequences, codon_index):
    all_codon_indices = []
    for sequence in sequences:
        codon_indices = []
        for i in range(0, len(sequence), 3):
            codon = sequence[i:i+3]
            if len(codon) == 3:
                if set(codon).issubset(set('ATCG')):
                    codon_indices.append(codon_index[codon])
                else:
                    raise ValueError('Invalid nucleotide character in sequence: {}'.format(codon))
        all_codon_indices.append(codon_indices)
    return all_codon_indices


test_sequences_rna = encode_sequences_rna(seq_test, codon_index)
print(test_sequences_rna[0])

# Sequences Length
min_length_rna, max_length_rna, median_length_rna = length(test_sequences_rna)
print("Taille Maximale des séquences : ", max_length_rna)

max_length_rna=770
test_padded_arn = pad_sequences(test_sequences_rna, maxlen=(max_length_rna), padding="post", truncating="post")

print("Test: ", test_padded_arn.shape)

model_arn_lstm = keras.models.load_model('/content/drive/MyDrive/Misclassified/Notebooks/Saved_models/ARN_Bi-LSTM')

zoonotic_lstm = model_arn_lstm.predict(test_padded_arn) 

def getResultsARN(y_test, X_test, predictions):

  tiers = []
  pred_class = []
  pred_max = []
  pred_avian = []
  pred_human = []
  pred_swine = []
  seq_arn = []
  host = []

  for i in range(len(y_test)):
    host.append(y_test[i])
  i=0
  for i in range(len(X_test)):
    seq_arn.append(X_test[i])  
  i=0 
  for i in range(len(predictions)):
    pred = predictions[i]

    av = pred[0]
    hu = pred[1]
    sw = pred[2]
    pred_avian.append(av.round(3))
    pred_human.append(hu.round(3))
    pred_swine.append(sw.round(3))

    max = pred.max()
    pred_max.append(max.round(3))

    if (max == av):
      classe = 'Avian'
    elif (max == hu):
      classe = 'Human'
    elif (max == sw):
      classe = 'Swine'
    pred_class.append(classe)

    if (max >=0.95 and max <=1):
      tier = '[95-100]'
    elif (max >=0.90 and max <0.95):
      tier = '[90-95]'
    elif (max >=0.85 and max <0.90):
      tier = '[85-90]'
    elif (max >=0.80 and max <0.85):
      tier = '[80-85]'
    elif (max >=0.75 and max <0.80):
      tier = '[75-80]'
    elif (max >=0.70 and max <0.75):
      tier = '[70-75]'
    elif (max >=0.65 and max <0.70):
      tier = '[65-70]'
    elif (max >=0.60 and max <0.65):
      tier = '[60-65]'
    elif (max >=0.55 and max <0.60):
      tier = '[55-60]'
    elif (max >=0.50 and max <0.55):
      tier = '[50-55]'      
    elif (max >=0.45 and max <0.50):
      tier = '[45-50]'
    elif (max >=0.40 and max <0.45):
      tier = '[40-45]'   
    elif (max >=0.35 and max <0.40):
      tier = '[35-40]'  
    elif (max >=0.30 and max <0.35):
      tier = '[30-35]' 

    tiers.append(tier)

  return(tiers, pred_class, pred_max, pred_avian, pred_human, pred_swine, seq_arn, host)

def toDataframesARN(tiers, pred_class, pred_max, pred_avian, pred_human, pred_swine, seq_arn, host):

  df = pd.DataFrame(columns=['tiers', 'pred_class', 'pred_max', 'pred_avian', 'pred_human', 'pred_swine', 'seq_arn', 'host'])
  df['tiers'] = tiers
  df['pred_class'] = pred_class
  df['pred_max'] = pred_max
  df['pred_avian'] = pred_avian
  df['pred_human'] = pred_human
  df['pred_swine'] = pred_swine
  df['seq_arn'] = seq_arn
  df['host'] = host

  return(df)

tiers_lstm_arn, pred_class_lstm_arn, pred_max_lstm_arn, pred_avian_lstm_arn, pred_human_lstm_arn, pred_swine_lstm_arn, seq_arn_lstm_arn, host_lstm_arn = getResultsARN(y_test, X_test, zoonotic_lstm)

df_zoonotic_arn_lstm = toDataframesARN(tiers_lstm_arn, pred_class_lstm_arn, pred_max_lstm_arn, pred_avian_lstm_arn, pred_human_lstm_arn, pred_swine_lstm_arn, seq_arn_lstm_arn, host_lstm_arn)

df_zoonotic_arn_lstm

#### %

df=df_zoonotic_arn_lstm
df['group'] = df.apply(lambda x: x['host'] if x['host'] == x['pred_class'] else f"{x['host']}_{x['pred_class']}", axis=1)
grouped = df.groupby('group').size().reset_index(name='count')
grouped['percentage'] = grouped['count'] / len(df) * 100

print(grouped)

### Transmission_to_Human Swine

#### Open Reading Frame

def codonStart(X,y):
  seq = X
  host = y.to_list()

  N = []
  X_ = []
  y_ = []

  numero = 0
  numbis = 0
  for i in range(len(seq)):
    seq_ = seq[i]
    host_ = host[i]

    numero = 0
    numbis = 0
    while numero < len(seq_)-2:
        if seq_[numero:numero+3] == 'ATG':
            numbis = numero
            N.append(numbis)
            X_.append(seq_)
            y_.append(host_)

            break
        numero += 1
  return (X_, y_, N)

X_test, y_test, idxStart_test = codonStart(df_swine.Sequence, df_swine.Host)

nonStop = ['GCT', 'GCC', 'GCA', 'GCG', 'CGT', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG', 'AAT', 'AAC', 'GAT', 'GAC', 'TGT', 'TGC', 'CAA', 'CAG', 'GAA', 'GAG', 'GGT', 'GGC', 'GGA', 'GGG', 'CAT', 'CAC', 'ATT', 'ATC', 'ATA', 'TTA', 'TTG', 'CTT', 'CTC', 'CTA', 'CTG', 'AAA', 'AAG', 'ATG', 'TTT', 'TTC', 'CCT', 'CCC', 'CCA', 'CCG', 'TCT', 'TCC', 'TCA', 'TCG', 'AGT', 'AGC', 'ACT', 'ACC', 'ACA', 'ACG', 'TGG', 'TAT', 'TAC', 'GTT', 'GTC', 'GTA', 'GTG']
stop = ['TAG', 'TGA', 'TAA']

def toSeq(X, N):
  seq_ = []
  tmp = []
  for i in range(len(X)):
    seq = X[i]
    numbis = N[i]
    while numbis < len(seq)-2:
      if seq[numbis:numbis+3] in nonStop:
        tmp += seq[numbis:numbis+3]
      elif seq[numbis:numbis+3] in stop:
        break

      numbis += 3
    str = ""
    seq_.append(str.join(tmp))
    tmp=[]

  return(seq_)

seq_test = toSeq(X_test, idxStart_test)

#### Length

def length(data):
  length = []
  for i in range(len(data)):
    length.append(len(data[i]))

  min = int(np.min(length))
  max = int(np.max(length))
  median = int(np.median(length))

  return (min, max, median)

min_length, max_length, median_length = length(seq_test)

print("Taille Minimale des séquences : ", min_length)
print("Taille Maximale des séquences : ", max_length)

#### Labels

le = LabelEncoder()

test_labels = le.fit_transform(y_test)
test_labels = to_categorical(test_labels)

print("Test: ", test_labels.shape)

#### RNA

# Define a dictionary mapping each codon to a unique index
codon_index = {
    'TTT': 1, 'TTC': 2, 'TTA': 3, 'TTG': 4, 'CTT': 5, 'CTC': 6, 'CTA': 7, 'CTG': 8, 'ATT': 9, 'ATC': 10, 'ATA': 11, 'ATG': 12, 'GTT': 13, 'GTC': 14, 'GTA': 15, 'GTG': 16, 'TCT': 17, 'TCC': 18, 'TCA': 19, 'TCG': 20, 'CCT': 21, 'CCC': 22, 'CCA': 23, 'CCG': 24, 'ACT': 25, 'ACC': 26, 'ACA': 27, 'ACG': 28, 'GCT': 29, 'GCC': 30, 'GCA': 31, 'GCG': 32, 'TAT': 33, 'TAC': 34, 'CAT': 35, 'CAC': 36, 'CAA': 37, 'CAG': 38, 'AAT': 39, 'AAC': 40, 'AAA': 41, 'AAG': 42, 'GAT': 43, 'GAC': 44, 'GAA': 45, 'GAG': 46, 'TGT': 47, 'TGC': 48, 'TGG': 49, 'CGT': 50, 'CGC': 51, 'CGA': 52, 'CGG': 53, 'AGT': 54, 'AGC': 55, 'AGA': 56, 'AGG': 57, 'GGT': 58, 'GGC': 59, 'GGA': 60, 'GGG': 61
}

# Define a function that encodes RNA sequences using the codon index
def encode_sequences_rna(sequences, codon_index):
    all_codon_indices = []
    for sequence in sequences:
        codon_indices = []
        for i in range(0, len(sequence), 3):
            codon = sequence[i:i+3]
            if len(codon) == 3:
                if set(codon).issubset(set('ATCG')):
                    codon_indices.append(codon_index[codon])
                else:
                    raise ValueError('Invalid nucleotide character in sequence: {}'.format(codon))
        all_codon_indices.append(codon_indices)
    return all_codon_indices


test_sequences_rna = encode_sequences_rna(seq_test, codon_index)
print(test_sequences_rna[0])

# Sequences Length
min_length_rna, max_length_rna, median_length_rna = length(test_sequences_rna)
print("Taille Maximale des séquences : ", max_length_rna)

max_length_rna=770
test_padded_arn = pad_sequences(test_sequences_rna, maxlen=(max_length_rna), padding="post", truncating="post")

print("Test: ", test_padded_arn.shape)

model_arn_lstm = keras.models.load_model('/content/drive/MyDrive/Misclassified/Notebooks/Saved_models/ARN_Bi-LSTM')

zoonotic_lstm = model_arn_lstm.predict(test_padded_arn) 

def getResultsARN(y_test, X_test, predictions):

  tiers = []
  pred_class = []
  pred_max = []
  pred_avian = []
  pred_human = []
  pred_swine = []
  seq_arn = []
  host = []

  for i in range(len(y_test)):
    host.append(y_test[i])
  i=0
  for i in range(len(X_test)):
    seq_arn.append(X_test[i])  
  i=0 
  for i in range(len(predictions)):
    pred = predictions[i]

    av = pred[0]
    hu = pred[1]
    sw = pred[2]
    pred_avian.append(av.round(3))
    pred_human.append(hu.round(3))
    pred_swine.append(sw.round(3))

    max = pred.max()
    pred_max.append(max.round(3))

    if (max == av):
      classe = 'Avian'
    elif (max == hu):
      classe = 'Human'
    elif (max == sw):
      classe = 'Swine'
    pred_class.append(classe)

    if (max >=0.95 and max <=1):
      tier = '[95-100]'
    elif (max >=0.90 and max <0.95):
      tier = '[90-95]'
    elif (max >=0.85 and max <0.90):
      tier = '[85-90]'
    elif (max >=0.80 and max <0.85):
      tier = '[80-85]'
    elif (max >=0.75 and max <0.80):
      tier = '[75-80]'
    elif (max >=0.70 and max <0.75):
      tier = '[70-75]'
    elif (max >=0.65 and max <0.70):
      tier = '[65-70]'
    elif (max >=0.60 and max <0.65):
      tier = '[60-65]'
    elif (max >=0.55 and max <0.60):
      tier = '[55-60]'
    elif (max >=0.50 and max <0.55):
      tier = '[50-55]'      
    elif (max >=0.45 and max <0.50):
      tier = '[45-50]'
    elif (max >=0.40 and max <0.45):
      tier = '[40-45]'   
    elif (max >=0.35 and max <0.40):
      tier = '[35-40]'  
    elif (max >=0.30 and max <0.35):
      tier = '[30-35]' 

    tiers.append(tier)

  return(tiers, pred_class, pred_max, pred_avian, pred_human, pred_swine, seq_arn, host)

def toDataframesARN(tiers, pred_class, pred_max, pred_avian, pred_human, pred_swine, seq_arn, host):

  df = pd.DataFrame(columns=['tiers', 'pred_class', 'pred_max', 'pred_avian', 'pred_human', 'pred_swine', 'seq_arn', 'host'])
  df['tiers'] = tiers
  df['pred_class'] = pred_class
  df['pred_max'] = pred_max
  df['pred_avian'] = pred_avian
  df['pred_human'] = pred_human
  df['pred_swine'] = pred_swine
  df['seq_arn'] = seq_arn
  df['host'] = host

  return(df)

tiers_lstm_arn, pred_class_lstm_arn, pred_max_lstm_arn, pred_avian_lstm_arn, pred_human_lstm_arn, pred_swine_lstm_arn, seq_arn_lstm_arn, host_lstm_arn = getResultsARN(y_test, X_test, zoonotic_lstm)

df_zoonotic_arn_lstm = toDataframesARN(tiers_lstm_arn, pred_class_lstm_arn, pred_max_lstm_arn, pred_avian_lstm_arn, pred_human_lstm_arn, pred_swine_lstm_arn, seq_arn_lstm_arn, host_lstm_arn)

df_zoonotic_arn_lstm

#### %

df=df_zoonotic_arn_lstm
df['group'] = df.apply(lambda x: x['host'] if x['host'] == x['pred_class'] else f"{x['host']}_{x['pred_class']}", axis=1)
grouped = df.groupby('group').size().reset_index(name='count')
grouped['percentage'] = grouped['count'] / len(df) * 100

print(grouped)

## Re-Test H1N1_2009

### H1N1_2009 & test_set

test_set = pd.read_excel('/content/drive/MyDrive/Misclassified/Data/Train_Val_Test/test_df.xlsx')
test_set = test_set.rename(columns={'Segment': 'Gene'})
test_set = test_set.rename(columns={'Accession': 'Accession_number'})
test_set['Gene'].fillna('NA', inplace=True)
test_set['State']='Old'
test_set.head()

zoonotic_seq_1 = pd.read_excel('/content/drive/MyDrive/Misclassified/Data/Zoonotic_Viruses/H1N1_2009.xlsx')
zoonotic_seq_1['Gene'].fillna('NA', inplace=True)

zoonotic_seq_1['Host']='Swine'
zoonotic_seq_1['State']='New'

zoonotic_seq_1 = zoonotic_seq_1.drop('Virus_Name', axis=1)
zoonotic_seq_1 = zoonotic_seq_1.drop('Taxonomy', axis=1)
zoonotic_seq_1 = zoonotic_seq_1.drop('Detected_in', axis=1)
zoonotic_seq_1 = zoonotic_seq_1.drop('Reference', axis=1)

column_names = test_set.columns

zoonotic_seq_1 = zoonotic_seq_1.reindex(columns=column_names)
zoonotic_seq_1.head()

len(zoonotic_seq_1)

df_concat = pd.concat([zoonotic_seq_1, test_set], ignore_index=True)
df_concat

### Open Reading Frame

def codonStart(X,y):
  seq = X
  host = y.to_list()

  N = []
  X_ = []
  y_ = []

  numero = 0
  numbis = 0
  for i in range(len(seq)):
    seq_ = seq[i]
    host_ = host[i]

    numero = 0
    numbis = 0
    while numero < len(seq_)-2:
        if seq_[numero:numero+3] == 'ATG':
            numbis = numero
            N.append(numbis)
            X_.append(seq_)
            y_.append(host_)

            break
        numero += 1
  return (X_, y_, N)

X_test, y_test, idxStart_test = codonStart(df_concat.Sequence, df_concat.Host)

nonStop = ['GCT', 'GCC', 'GCA', 'GCG', 'CGT', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG', 'AAT', 'AAC', 'GAT', 'GAC', 'TGT', 'TGC', 'CAA', 'CAG', 'GAA', 'GAG', 'GGT', 'GGC', 'GGA', 'GGG', 'CAT', 'CAC', 'ATT', 'ATC', 'ATA', 'TTA', 'TTG', 'CTT', 'CTC', 'CTA', 'CTG', 'AAA', 'AAG', 'ATG', 'TTT', 'TTC', 'CCT', 'CCC', 'CCA', 'CCG', 'TCT', 'TCC', 'TCA', 'TCG', 'AGT', 'AGC', 'ACT', 'ACC', 'ACA', 'ACG', 'TGG', 'TAT', 'TAC', 'GTT', 'GTC', 'GTA', 'GTG']
stop = ['TAG', 'TGA', 'TAA']

def toSeq(X, N):
  seq_ = []
  tmp = []
  for i in range(len(X)):
    seq = X[i]
    numbis = N[i]
    while numbis < len(seq)-2:
      if seq[numbis:numbis+3] in nonStop:
        tmp += seq[numbis:numbis+3]
      elif seq[numbis:numbis+3] in stop:
        break

      numbis += 3
    str = ""
    seq_.append(str.join(tmp))
    tmp=[]

  return(seq_)

seq_test = toSeq(X_test, idxStart_test)

### Length

def length(data):
  length = []
  for i in range(len(data)):
    length.append(len(data[i]))

  min = int(np.min(length))
  max = int(np.max(length))
  median = int(np.median(length))

  return (min, max, median)

min_length, max_length, median_length = length(seq_test)

print("Taille Minimale des séquences : ", min_length)
print("Taille Maximale des séquences : ", max_length)

### Labels

le = LabelEncoder()

test_labels = le.fit_transform(y_test)
test_labels = to_categorical(test_labels)

print("Test: ", test_labels.shape)

### RNA

codon_index = {
    'TTT': 1, 'TTC': 2, 'TTA': 3, 'TTG': 4, 'CTT': 5, 'CTC': 6, 'CTA': 7, 'CTG': 8, 'ATT': 9, 'ATC': 10, 'ATA': 11, 'ATG': 12, 'GTT': 13, 'GTC': 14, 'GTA': 15, 'GTG': 16, 'TCT': 17, 'TCC': 18, 'TCA': 19, 'TCG': 20, 'CCT': 21, 'CCC': 22, 'CCA': 23, 'CCG': 24, 'ACT': 25, 'ACC': 26, 'ACA': 27, 'ACG': 28, 'GCT': 29, 'GCC': 30, 'GCA': 31, 'GCG': 32, 'TAT': 33, 'TAC': 34, 'CAT': 35, 'CAC': 36, 'CAA': 37, 'CAG': 38, 'AAT': 39, 'AAC': 40, 'AAA': 41, 'AAG': 42, 'GAT': 43, 'GAC': 44, 'GAA': 45, 'GAG': 46, 'TGT': 47, 'TGC': 48, 'TGG': 49, 'CGT': 50, 'CGC': 51, 'CGA': 52, 'CGG': 53, 'AGT': 54, 'AGC': 55, 'AGA': 56, 'AGG': 57, 'GGT': 58, 'GGC': 59, 'GGA': 60, 'GGG': 61
}

def encode_sequences_rna(sequences, codon_index):
    all_codon_indices = []
    for sequence in sequences:
        codon_indices = []
        for i in range(0, len(sequence), 3):
            codon = sequence[i:i+3]
            if len(codon) == 3:
                if set(codon).issubset(set('ATCG')):
                    codon_indices.append(codon_index[codon])
                else:
                    raise ValueError('Invalid nucleotide character in sequence: {}'.format(codon))
        all_codon_indices.append(codon_indices)
    return all_codon_indices


test_sequences_rna = encode_sequences_rna(seq_test, codon_index)
print(test_sequences_rna[0])

min_length_rna, max_length_rna, median_length_rna = length(test_sequences_rna)
print("Taille Maximale des séquences : ", max_length_rna)

max_length_rna=770
test_padded_arn = pad_sequences(test_sequences_rna, maxlen=(max_length_rna), padding="post", truncating="post")

print("Test: ", test_padded_arn.shape)

model_arn_lstm = keras.models.load_model('/content/drive/MyDrive/Misclassified/Notebooks/Saved_models/ARN_Bi-LSTM')

zoonotic_lstm = model_arn_lstm.predict(test_padded_arn) 

def getResultsARN(y_test, X_test, predictions):

  tiers = []
  pred_class = []
  pred_max = []
  pred_avian = []
  pred_human = []
  pred_swine = []
  seq_arn = []
  host = []

  for i in range(len(y_test)):
    host.append(y_test[i])
  i=0
  for i in range(len(X_test)):
    seq_arn.append(X_test[i])  
  i=0 
  for i in range(len(predictions)):
    pred = predictions[i]

    av = pred[0]
    hu = pred[1]
    sw = pred[2]
    pred_avian.append(av.round(3))
    pred_human.append(hu.round(3))
    pred_swine.append(sw.round(3))

    max = pred.max()
    pred_max.append(max.round(3))

    if (max == av):
      classe = 'Avian'
    elif (max == hu):
      classe = 'Human'
    elif (max == sw):
      classe = 'Swine'
    pred_class.append(classe)

    if (max >=0.95 and max <=1):
      tier = '[95-100]'
    elif (max >=0.90 and max <0.95):
      tier = '[90-95]'
    elif (max >=0.85 and max <0.90):
      tier = '[85-90]'
    elif (max >=0.80 and max <0.85):
      tier = '[80-85]'
    elif (max >=0.75 and max <0.80):
      tier = '[75-80]'
    elif (max >=0.70 and max <0.75):
      tier = '[70-75]'
    elif (max >=0.65 and max <0.70):
      tier = '[65-70]'
    elif (max >=0.60 and max <0.65):
      tier = '[60-65]'
    elif (max >=0.55 and max <0.60):
      tier = '[55-60]'
    elif (max >=0.50 and max <0.55):
      tier = '[50-55]'      
    elif (max >=0.45 and max <0.50):
      tier = '[45-50]'
    elif (max >=0.40 and max <0.45):
      tier = '[40-45]'   
    elif (max >=0.35 and max <0.40):
      tier = '[35-40]'  
    elif (max >=0.30 and max <0.35):
      tier = '[30-35]' 

    tiers.append(tier)

  return(tiers, pred_class, pred_max, pred_avian, pred_human, pred_swine, seq_arn, host)

def toDataframesARN(tiers, pred_class, pred_max, pred_avian, pred_human, pred_swine, seq_arn, host):

  df = pd.DataFrame(columns=['tiers', 'pred_class', 'pred_max', 'pred_avian', 'pred_human', 'pred_swine', 'seq_arn', 'host'])
  df['tiers'] = tiers
  df['pred_class'] = pred_class
  df['pred_max'] = pred_max
  df['pred_avian'] = pred_avian
  df['pred_human'] = pred_human
  df['pred_swine'] = pred_swine
  df['seq_arn'] = seq_arn
  df['host'] = host

  return(df)

tiers_lstm_arn, pred_class_lstm_arn, pred_max_lstm_arn, pred_avian_lstm_arn, pred_human_lstm_arn, pred_swine_lstm_arn, seq_arn_lstm_arn, host_lstm_arn = getResultsARN(y_test, X_test, zoonotic_lstm)

df_zoonotic_arn_lstm = toDataframesARN(tiers_lstm_arn, pred_class_lstm_arn, pred_max_lstm_arn, pred_avian_lstm_arn, pred_human_lstm_arn, pred_swine_lstm_arn, seq_arn_lstm_arn, host_lstm_arn)

df_zoonotic_arn_lstm

df=zoonotic_seq_1
df= df.drop("Host", axis=1)
df= df.drop("Sequence", axis=1)
df.head()

result = pd.concat([df, df_zoonotic_arn_lstm], axis=1).reindex(df_zoonotic_arn_lstm.index)
result

result.to_excel('/content/drive/MyDrive/Misclassified/Notebooks/df_zoonotic_test_arn_lstm.xlsx')

len(result)

### Latent Space

df_zoonotic_test_arn_lstm = pd.read_excel('/content/drive/MyDrive/Misclassified/Notebooks/df_zoonotic_test_arn_lstm.xlsx')

latent_space_model = tf.keras.models.Model(inputs=model_arn_lstm.input, outputs=model_arn_lstm.layers[-1].output)

latent_space = latent_space_model.predict(test_padded_arn, batch_size=32)

print("Taille de l'espace latent avant réduction : ", latent_space.shape)

mapper_rna = umap.UMAP(n_neighbors=15, min_dist=0.8, n_components=2, metric='canberra', random_state=42).fit(latent_space)

hover_data_rna = pd.DataFrame({'index':np.arange(len(result)),'tiers':result['tiers'], 'host':result['host'], 'pred_class':result['pred_class']})
p_rna = umap.plot.interactive(mapper_rna, labels=result['pred_class'], hover_data=hover_data_rna,color_key_cmap='prism', point_size=3)
output_notebook()
show(p_rna)

hover_data_rna = pd.DataFrame({'index':np.arange(len(result[0:len(zoonotic_seq_1)])),'tiers':result[0:len(zoonotic_seq_1)]['tiers'],'gene':result[0:len(zoonotic_seq_1)]['Gene'], 'host':result[0:len(zoonotic_seq_1)]['host'], 'pred_class':result[0:len(zoonotic_seq_1)]['pred_class']})
p_rna = umap.plot.interactive(mapper_rna,  labels=result[0:len(zoonotic_seq_1)]['State'], hover_data=hover_data_rna,color_key_cmap='prism', point_size=5, theme='fire')

output_notebook()
show(p_rna)

hover_data_rna = pd.DataFrame({'index':np.arange(len(result)),'tiers':result['tiers'], 'host':result['host'], 'pred_class':result['pred_class']})
p_rna = umap.plot.interactive(mapper_rna, labels=result['tiers'], hover_data=hover_data_rna,color_key_cmap='ocean', point_size=2.5)
output_notebook()
show(p_rna)

### K-means

X_rna=mapper_rna.embedding_
X_rna

from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=3)
kmeans.fit(X_rna)
y_kmeans_rna = kmeans.predict(X_rna)

len(zoonotic_seq_1)

for i in range(len(zoonotic_seq_1)):
  print(y_kmeans_rna[i])

plt.scatter(X_rna[:, 0], X_rna[:, 1], c=y_kmeans_rna, s=10, cmap='viridis')

centers_rna = kmeans.cluster_centers_
plt.scatter(centers_rna[:, 0], centers_rna[:, 1], c='black', s=200, alpha=0.5);
for i in range(len(zoonotic_seq_1)):
  plt.scatter(X_rna[i, 0], X_rna[i, 1], s=10)

centers_rna

import numpy as np
dist=[]
for i in range(len(zoonotic_seq_1)):
  for j in range(len(centers_rna)):
    dist.append(np.linalg.norm(centers_rna[j] - X_rna[i]))
shape = (len(zoonotic_seq_1),len(centers_rna))
dist_ = np.array(dist)
dist_.reshape(shape)


dist_df = pd.DataFrame(dist_.reshape(shape), columns = ['distAvian','distHuman','distSwine'])
dist_df

zoonotic_seq_1

dist_H1N1_2009 = zoonotic_seq_1.merge(dist_df, left_index=True, right_index=True)
dist_H1N1_2009

dist_H1N1_2009.to_excel('/content/drive/MyDrive/Misclassified/Notebooks/kmeans_dist_euc/dist_H1N1_2009.xlsx')

## Re-Test Transmission_to_Human

### Transmission_to_Human & test_set

test_set = pd.read_excel('/content/drive/MyDrive/Misclassified/Data/Train_Val_Test/test_df.xlsx')
test_set = test_set.rename(columns={'Segment': 'Gene'})
test_set = test_set.rename(columns={'Accession': 'Accession_number'})
test_set['Gene'].fillna('NA', inplace=True)
test_set['State']='Old'
test_set.head()

zoonotic_seq_2 = pd.read_excel('/content/drive/MyDrive/Misclassified/Data/Zoonotic_Viruses/Transmission_to_Human.xlsx')
zoonotic_seq_2['Gene'].fillna('NA', inplace=True)

zoonotic_seq_2['State']='New'
zoonotic_seq_2 = zoonotic_seq_2.rename(columns={'Origin': 'Host'})

zoonotic_seq_2 = zoonotic_seq_2.drop('Virus_Name', axis=1)
zoonotic_seq_2 = zoonotic_seq_2.drop('Virus_type', axis=1)

zoonotic_seq_2 = zoonotic_seq_2.drop('Taxon', axis=1)
zoonotic_seq_2 = zoonotic_seq_2.drop('Detected_in', axis=1)
zoonotic_seq_2 = zoonotic_seq_2.drop('Reference', axis=1)

column_names = test_set.columns

zoonotic_seq_2 = zoonotic_seq_2.reindex(columns=column_names)
zoonotic_seq_2.head()

len(zoonotic_seq_2)

df_concat = pd.concat([zoonotic_seq_2, test_set], ignore_index=True)
df_concat

### Open Reading Frame

def codonStart(X,y):
  seq = X
  host = y.to_list()

  N = []
  X_ = []
  y_ = []

  numero = 0
  numbis = 0
  for i in range(len(seq)):
    seq_ = seq[i]
    host_ = host[i]

    numero = 0
    numbis = 0
    while numero < len(seq_)-2:
        if seq_[numero:numero+3] == 'ATG':
            numbis = numero
            N.append(numbis)
            X_.append(seq_)
            y_.append(host_)

            break
        numero += 1
  return (X_, y_, N)

X_test, y_test, idxStart_test = codonStart(df_concat.Sequence, df_concat.Host)

nonStop = ['GCT', 'GCC', 'GCA', 'GCG', 'CGT', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG', 'AAT', 'AAC', 'GAT', 'GAC', 'TGT', 'TGC', 'CAA', 'CAG', 'GAA', 'GAG', 'GGT', 'GGC', 'GGA', 'GGG', 'CAT', 'CAC', 'ATT', 'ATC', 'ATA', 'TTA', 'TTG', 'CTT', 'CTC', 'CTA', 'CTG', 'AAA', 'AAG', 'ATG', 'TTT', 'TTC', 'CCT', 'CCC', 'CCA', 'CCG', 'TCT', 'TCC', 'TCA', 'TCG', 'AGT', 'AGC', 'ACT', 'ACC', 'ACA', 'ACG', 'TGG', 'TAT', 'TAC', 'GTT', 'GTC', 'GTA', 'GTG']
stop = ['TAG', 'TGA', 'TAA']

def toSeq(X, N):
  seq_ = []
  tmp = []
  for i in range(len(X)):
    seq = X[i]
    numbis = N[i]
    while numbis < len(seq)-2:
      if seq[numbis:numbis+3] in nonStop:
        tmp += seq[numbis:numbis+3]
      elif seq[numbis:numbis+3] in stop:
        break

      numbis += 3
    str = ""
    seq_.append(str.join(tmp))
    tmp=[]

  return(seq_)

seq_test = toSeq(X_test, idxStart_test)

### Length

def length(data):
  length = []
  for i in range(len(data)):
    length.append(len(data[i]))

  min = int(np.min(length))
  max = int(np.max(length))
  median = int(np.median(length))

  return (min, max, median)

min_length, max_length, median_length = length(seq_test)

print("Taille Minimale des séquences : ", min_length)
print("Taille Maximale des séquences : ", max_length)

### Labels

le = LabelEncoder()

test_labels = le.fit_transform(y_test)
test_labels = to_categorical(test_labels)

print("Test: ", test_labels.shape)

### RNA

codon_index = {
    'TTT': 1, 'TTC': 2, 'TTA': 3, 'TTG': 4, 'CTT': 5, 'CTC': 6, 'CTA': 7, 'CTG': 8, 'ATT': 9, 'ATC': 10, 'ATA': 11, 'ATG': 12, 'GTT': 13, 'GTC': 14, 'GTA': 15, 'GTG': 16, 'TCT': 17, 'TCC': 18, 'TCA': 19, 'TCG': 20, 'CCT': 21, 'CCC': 22, 'CCA': 23, 'CCG': 24, 'ACT': 25, 'ACC': 26, 'ACA': 27, 'ACG': 28, 'GCT': 29, 'GCC': 30, 'GCA': 31, 'GCG': 32, 'TAT': 33, 'TAC': 34, 'CAT': 35, 'CAC': 36, 'CAA': 37, 'CAG': 38, 'AAT': 39, 'AAC': 40, 'AAA': 41, 'AAG': 42, 'GAT': 43, 'GAC': 44, 'GAA': 45, 'GAG': 46, 'TGT': 47, 'TGC': 48, 'TGG': 49, 'CGT': 50, 'CGC': 51, 'CGA': 52, 'CGG': 53, 'AGT': 54, 'AGC': 55, 'AGA': 56, 'AGG': 57, 'GGT': 58, 'GGC': 59, 'GGA': 60, 'GGG': 61
}

def encode_sequences_rna(sequences, codon_index):
    all_codon_indices = []
    for sequence in sequences:
        codon_indices = []
        for i in range(0, len(sequence), 3):
            codon = sequence[i:i+3]
            if len(codon) == 3:
                if set(codon).issubset(set('ATCG')):
                    codon_indices.append(codon_index[codon])
                else:
                    raise ValueError('Invalid nucleotide character in sequence: {}'.format(codon))
        all_codon_indices.append(codon_indices)
    return all_codon_indices


test_sequences_rna = encode_sequences_rna(seq_test, codon_index)
print(test_sequences_rna[0])

min_length_rna, max_length_rna, median_length_rna = length(test_sequences_rna)
print("Taille Maximale des séquences : ", max_length_rna)

max_length_rna=770
test_padded_arn = pad_sequences(test_sequences_rna, maxlen=(max_length_rna), padding="post", truncating="post")

print("Test: ", test_padded_arn.shape)

model_arn_lstm = keras.models.load_model('/content/drive/MyDrive/Misclassified/Notebooks/Saved_models/ARN_Bi-LSTM')

zoonotic_lstm = model_arn_lstm.predict(test_padded_arn) 

def getResultsARN(y_test, X_test, predictions):

  tiers = []
  pred_class = []
  pred_max = []
  pred_avian = []
  pred_human = []
  pred_swine = []
  seq_arn = []
  host = []

  for i in range(len(y_test)):
    host.append(y_test[i])
  i=0
  for i in range(len(X_test)):
    seq_arn.append(X_test[i])  
  i=0 
  for i in range(len(predictions)):
    pred = predictions[i]

    av = pred[0]
    hu = pred[1]
    sw = pred[2]
    pred_avian.append(av.round(3))
    pred_human.append(hu.round(3))
    pred_swine.append(sw.round(3))

    max = pred.max()
    pred_max.append(max.round(3))

    if (max == av):
      classe = 'Avian'
    elif (max == hu):
      classe = 'Human'
    elif (max == sw):
      classe = 'Swine'
    pred_class.append(classe)

    if (max >=0.95 and max <=1):
      tier = '[95-100]'
    elif (max >=0.90 and max <0.95):
      tier = '[90-95]'
    elif (max >=0.85 and max <0.90):
      tier = '[85-90]'
    elif (max >=0.80 and max <0.85):
      tier = '[80-85]'
    elif (max >=0.75 and max <0.80):
      tier = '[75-80]'
    elif (max >=0.70 and max <0.75):
      tier = '[70-75]'
    elif (max >=0.65 and max <0.70):
      tier = '[65-70]'
    elif (max >=0.60 and max <0.65):
      tier = '[60-65]'
    elif (max >=0.55 and max <0.60):
      tier = '[55-60]'
    elif (max >=0.50 and max <0.55):
      tier = '[50-55]'      
    elif (max >=0.45 and max <0.50):
      tier = '[45-50]'
    elif (max >=0.40 and max <0.45):
      tier = '[40-45]'   
    elif (max >=0.35 and max <0.40):
      tier = '[35-40]'  
    elif (max >=0.30 and max <0.35):
      tier = '[30-35]' 

    tiers.append(tier)

  return(tiers, pred_class, pred_max, pred_avian, pred_human, pred_swine, seq_arn, host)

def toDataframesARN(tiers, pred_class, pred_max, pred_avian, pred_human, pred_swine, seq_arn, host):

  df = pd.DataFrame(columns=['tiers', 'pred_class', 'pred_max', 'pred_avian', 'pred_human', 'pred_swine', 'seq_arn', 'host'])
  df['tiers'] = tiers
  df['pred_class'] = pred_class
  df['pred_max'] = pred_max
  df['pred_avian'] = pred_avian
  df['pred_human'] = pred_human
  df['pred_swine'] = pred_swine
  df['seq_arn'] = seq_arn
  df['host'] = host

  return(df)

tiers_lstm_arn, pred_class_lstm_arn, pred_max_lstm_arn, pred_avian_lstm_arn, pred_human_lstm_arn, pred_swine_lstm_arn, seq_arn_lstm_arn, host_lstm_arn = getResultsARN(y_test, X_test, zoonotic_lstm)

df_zoonotic_arn_lstm = toDataframesARN(tiers_lstm_arn, pred_class_lstm_arn, pred_max_lstm_arn, pred_avian_lstm_arn, pred_human_lstm_arn, pred_swine_lstm_arn, seq_arn_lstm_arn, host_lstm_arn)

df_zoonotic_arn_lstm

df=zoonotic_seq_2
df= df.drop("Host", axis=1)
df= df.drop("Sequence", axis=1)
df.head()

result = pd.concat([df, df_zoonotic_arn_lstm], axis=1).reindex(df_zoonotic_arn_lstm.index)
result

result.to_excel('/content/drive/MyDrive/Misclassified/Notebooks/df_zoonotic_2_test_arn_lstm.xlsx')

len(result)

### Latent Space

df_zoonotic_test_arn_lstm = pd.read_excel('/content/drive/MyDrive/Misclassified/Notebooks/df_zoonotic_2_test_arn_lstm.xlsx')

latent_space_model = tf.keras.models.Model(inputs=model_arn_lstm.input, outputs=model_arn_lstm.layers[-1].output)

latent_space = latent_space_model.predict(test_padded_arn, batch_size=32)

print("Taille de l'espace latent avant réduction : ", latent_space.shape)

mapper_rna = umap.UMAP(n_neighbors=15, min_dist=0.8, n_components=2, metric='canberra', random_state=42).fit(latent_space)

hover_data_rna = pd.DataFrame({'index':np.arange(len(result)),'tiers':result['tiers'], 'host':result['host'], 'pred_class':result['pred_class']})
p_rna = umap.plot.interactive(mapper_rna, labels=result['pred_class'], hover_data=hover_data_rna,color_key_cmap='prism', point_size=3)
output_notebook()
show(p_rna)

hover_data_rna = pd.DataFrame({'index':np.arange(len(result[0:len(zoonotic_seq_2)])),'tiers':result[0:len(zoonotic_seq_2)]['tiers'],'gene':result[0:len(zoonotic_seq_2)]['Gene'], 'host':result[0:len(zoonotic_seq_2)]['host'], 'pred_class':result[0:len(zoonotic_seq_2)]['pred_class']})
p_rna = umap.plot.interactive(mapper_rna,  labels=result[0:len(zoonotic_seq_2)]['State'], hover_data=hover_data_rna,color_key_cmap='prism', point_size=5, theme='fire')

output_notebook()
show(p_rna)

hover_data_rna = pd.DataFrame({'index':np.arange(len(result)),'tiers':result['tiers'], 'host':result['host'], 'pred_class':result['pred_class']})
p_rna = umap.plot.interactive(mapper_rna, labels=result['tiers'], hover_data=hover_data_rna,color_key_cmap='ocean', point_size=2.5)
output_notebook()
show(p_rna)

Kmeans



### K-means

X_rna=mapper_rna.embedding_
X_rna

from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=3)
kmeans.fit(X_rna)
y_kmeans_rna = kmeans.predict(X_rna)

len(zoonotic_seq_2)

for i in range(len(zoonotic_seq_2)):
  print(y_kmeans_rna[i])

y_kmeans_rna[0], y_kmeans_rna[1], y_kmeans_rna[2], y_kmeans_rna[3], y_kmeans_rna[4]

plt.scatter(X_rna[:, 0], X_rna[:, 1], c=y_kmeans_rna, s=10, cmap='viridis')

centers_rna = kmeans.cluster_centers_
plt.scatter(centers_rna[:, 0], centers_rna[:, 1], c='black', s=200, alpha=0.5);
for i in range(len(zoonotic_seq_2)):
  plt.scatter(X_rna[i, 0], X_rna[i, 1], s=10)

centers_rna

import numpy as np
dist=[]
for i in range(len(zoonotic_seq_2)):
  for j in range(len(centers_rna)):
    dist.append(np.linalg.norm(centers_rna[j] - X_rna[i]))
#print(dist)
shape = (len(zoonotic_seq_2),len(centers_rna))
dist_ = np.array(dist)
dist_.reshape(shape)


dist_df = pd.DataFrame(dist_.reshape(shape), columns = ['distAvian','distHuman','distSwine'])
dist_df

zoonotic_seq_2

dist_Transmission_to_Human= zoonotic_seq_2.merge(dist_df, left_index=True, right_index=True)
dist_Transmission_to_Human

dist_Transmission_to_Human.to_excel('/content/drive/MyDrive/Misclassified/Notebooks/kmeans_dist_euc/dist_Transmission_to_Human.xlsx)
